{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part_A_Q1a.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gteavesOa9C",
        "outputId": "f3eb2749-be28-4462-fc85-26dbd3a2c373",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0NAhykuPvow",
        "outputId": "961e595f-ff04-429a-e1f6-54a7d4a455e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# RTX On\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        # Currently, memory growth needs to be the same across GPUs\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
        "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
        "    except RuntimeError as e:\n",
        "        # Memory growth must be set before GPUs have been initialized\n",
        "        print(e)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 Physical GPUs, 1 Logical GPUs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rT53SKjLPxbi"
      },
      "source": [
        "def load_data(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        try:\n",
        "            samples = pickle.load(fo)\n",
        "        except UnicodeDecodeError:  # python 3.x\n",
        "            fo.seek(0)\n",
        "            samples = pickle.load(fo, encoding='latin1')\n",
        "\n",
        "    data, labels = samples['data'], samples['labels']\n",
        "\n",
        "    data = np.array(data, dtype=np.float32) / 255\n",
        "    labels = np.array(labels, dtype=np.int32)\n",
        "    return data, labels"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvhYNuOpPy1q"
      },
      "source": [
        "def make_model(num_ch_c1, num_ch_c2, use_dropout):\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Input Layer\n",
        "    model.add(layers.Input(shape=(3072,)))\n",
        "    model.add(layers.Reshape(target_shape=(32, 32, 3), input_shape=(3072,)))\n",
        "    \n",
        "    # C₁ Convolutional Layer\n",
        "    model.add(layers.Conv2D(num_ch_c1, 9, padding='valid', activation='relu', input_shape=(None, None, 3)))\n",
        "\n",
        "    # S₁ Max Pooling Layer\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2), padding='valid'))\n",
        "    \n",
        "    # C₂ Convolutional Layer\n",
        "    model.add(layers.Conv2D(num_ch_c2, 5, padding='valid', activation='relu', input_shape=(None, None, 3)))\n",
        "\n",
        "    # S₂ Max Pooling Layer\n",
        "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2), padding='valid'))\n",
        "\n",
        "    # Flatten\n",
        "    model.add(layers.Flatten())\n",
        "    \n",
        "    # F₃ Fully-Connected Layer\n",
        "    model.add(layers.Dense(300, use_bias=True))  # Here no softmax because we have combined it with the loss   \n",
        "    \n",
        "    # F₄ Fully-Connected Layer \n",
        "    model.add(layers.Dense(10, use_bias=True, input_shape=(300,)))  # Here no softmax because we have combined it with the loss   \n",
        "        \n",
        "    return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyZgCf24P8io"
      },
      "source": [
        "seed = 0\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "num_ch_c1 = 50  # Question 2\n",
        "num_ch_c2 = 60  # Question 2\n",
        "\n",
        "epochs = 1000  # Fixed\n",
        "batch_size = 128  # Fixed\n",
        "learning_rate = 0.001\n",
        "\n",
        "optimizer_ = 'SGD'  # Question 3\n",
        "use_dropout = False  # Question 3(d) (see make_model)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqm0aPcuQAdu"
      },
      "source": [
        "model = make_model(num_ch_c1, num_ch_c2, use_dropout)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ptNL7lQQm2I"
      },
      "source": [
        "if optimizer_ == 'SGD':\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
        "elif optimizer_ == 'SGD-momentum':  # Question 3(a)\n",
        "    momentum = 0.1\n",
        "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
        "elif optimizer_ == 'RMSProp':  # Question 3(b)\n",
        "    optimizer = keras.optimizers.RMSProp(learning_rate=learning_rate)\n",
        "elif optimizer_ == 'Adam':  # Question 3(c)\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "else:\n",
        "    raise NotImplementedError(f'You do not need to handle [{optimizer_}] in this project.')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxaXEd0qUNGC"
      },
      "source": [
        "# Create folder to store models and results\n",
        "'''\n",
        "if not os.path.exists('./models'):\n",
        "    os.mkdir('./models')\n",
        "if not os.path.exists('./results'):\n",
        "    os.mkdir('./results')\n",
        "'''\n",
        "\n",
        "# Create folder to store one more level down\n",
        "if not os.path.exists(f'/content/gdrive/My Drive/Colab Output/models/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout'):\n",
        "    os.mkdir(f'/content/gdrive/My Drive/Colab Output/models/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout')\n",
        "if not os.path.exists(f'/content/gdrive/My Drive/Colab Output/models/{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout'):\n",
        "    os.mkdir(f'/content/gdrive/My Drive/Colab Output/models/{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf8l0ReZQqhN"
      },
      "source": [
        "'''\n",
        "Load Training and Test Datasets\n",
        "'''\n",
        "x_train, y_train = load_data('/content/gdrive/My Drive/Colab Notebooks/data_batch_1')\n",
        "x_test, y_test = load_data('/content/gdrive/My Drive/Colab Notebooks/test_batch_trim')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD-uzaYPQr89",
        "outputId": "d876448c-4b81-443e-b392-408076b0a3a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''\n",
        "Train Model\n",
        "'''\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics='accuracy')\n",
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 2.3122 - accuracy: 0.1059 - val_loss: 2.2994 - val_accuracy: 0.1300\n",
            "Epoch 2/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.2953 - accuracy: 0.1254 - val_loss: 2.2893 - val_accuracy: 0.1290\n",
            "Epoch 3/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.2863 - accuracy: 0.1331 - val_loss: 2.2818 - val_accuracy: 0.1370\n",
            "Epoch 4/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.2792 - accuracy: 0.1386 - val_loss: 2.2757 - val_accuracy: 0.1525\n",
            "Epoch 5/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.2728 - accuracy: 0.1484 - val_loss: 2.2694 - val_accuracy: 0.1635\n",
            "Epoch 6/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.2661 - accuracy: 0.1619 - val_loss: 2.2628 - val_accuracy: 0.1760\n",
            "Epoch 7/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.2588 - accuracy: 0.1720 - val_loss: 2.2555 - val_accuracy: 0.1880\n",
            "Epoch 8/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.2507 - accuracy: 0.1858 - val_loss: 2.2469 - val_accuracy: 0.1945\n",
            "Epoch 9/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.2410 - accuracy: 0.2010 - val_loss: 2.2362 - val_accuracy: 0.2115\n",
            "Epoch 10/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.2298 - accuracy: 0.2057 - val_loss: 2.2249 - val_accuracy: 0.2220\n",
            "Epoch 11/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.2178 - accuracy: 0.2145 - val_loss: 2.2118 - val_accuracy: 0.2185\n",
            "Epoch 12/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.2046 - accuracy: 0.2236 - val_loss: 2.1977 - val_accuracy: 0.2235\n",
            "Epoch 13/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.1907 - accuracy: 0.2256 - val_loss: 2.1835 - val_accuracy: 0.2305\n",
            "Epoch 14/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.1766 - accuracy: 0.2288 - val_loss: 2.1693 - val_accuracy: 0.2305\n",
            "Epoch 15/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.1625 - accuracy: 0.2363 - val_loss: 2.1549 - val_accuracy: 0.2350\n",
            "Epoch 16/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.1480 - accuracy: 0.2417 - val_loss: 2.1405 - val_accuracy: 0.2475\n",
            "Epoch 17/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.1335 - accuracy: 0.2445 - val_loss: 2.1253 - val_accuracy: 0.2445\n",
            "Epoch 18/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.1188 - accuracy: 0.2527 - val_loss: 2.1114 - val_accuracy: 0.2650\n",
            "Epoch 19/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.1049 - accuracy: 0.2600 - val_loss: 2.0976 - val_accuracy: 0.2710\n",
            "Epoch 20/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.0914 - accuracy: 0.2639 - val_loss: 2.0852 - val_accuracy: 0.2710\n",
            "Epoch 21/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.0788 - accuracy: 0.2654 - val_loss: 2.0714 - val_accuracy: 0.2690\n",
            "Epoch 22/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.0664 - accuracy: 0.2715 - val_loss: 2.0678 - val_accuracy: 0.2550\n",
            "Epoch 23/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.0550 - accuracy: 0.2749 - val_loss: 2.0505 - val_accuracy: 0.2620\n",
            "Epoch 24/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.0442 - accuracy: 0.2777 - val_loss: 2.0385 - val_accuracy: 0.2795\n",
            "Epoch 25/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.0341 - accuracy: 0.2807 - val_loss: 2.0441 - val_accuracy: 0.2645\n",
            "Epoch 26/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.0245 - accuracy: 0.2830 - val_loss: 2.0162 - val_accuracy: 0.2925\n",
            "Epoch 27/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 2.0153 - accuracy: 0.2893 - val_loss: 2.0106 - val_accuracy: 0.2745\n",
            "Epoch 28/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 2.0064 - accuracy: 0.2908 - val_loss: 2.0058 - val_accuracy: 0.2890\n",
            "Epoch 29/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9993 - accuracy: 0.2926 - val_loss: 1.9931 - val_accuracy: 0.2875\n",
            "Epoch 30/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9905 - accuracy: 0.2965 - val_loss: 1.9909 - val_accuracy: 0.2885\n",
            "Epoch 31/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9828 - accuracy: 0.3020 - val_loss: 1.9852 - val_accuracy: 0.2830\n",
            "Epoch 32/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9764 - accuracy: 0.3024 - val_loss: 1.9752 - val_accuracy: 0.2975\n",
            "Epoch 33/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9700 - accuracy: 0.3038 - val_loss: 1.9636 - val_accuracy: 0.3060\n",
            "Epoch 34/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9635 - accuracy: 0.3079 - val_loss: 1.9551 - val_accuracy: 0.3035\n",
            "Epoch 35/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9566 - accuracy: 0.3053 - val_loss: 1.9613 - val_accuracy: 0.3150\n",
            "Epoch 36/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9512 - accuracy: 0.3096 - val_loss: 1.9457 - val_accuracy: 0.3100\n",
            "Epoch 37/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9454 - accuracy: 0.3118 - val_loss: 1.9668 - val_accuracy: 0.2935\n",
            "Epoch 38/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9415 - accuracy: 0.3138 - val_loss: 1.9390 - val_accuracy: 0.3135\n",
            "Epoch 39/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.9354 - accuracy: 0.3143 - val_loss: 1.9452 - val_accuracy: 0.3040\n",
            "Epoch 40/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9310 - accuracy: 0.3143 - val_loss: 1.9411 - val_accuracy: 0.3120\n",
            "Epoch 41/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9269 - accuracy: 0.3143 - val_loss: 1.9847 - val_accuracy: 0.2775\n",
            "Epoch 42/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9235 - accuracy: 0.3188 - val_loss: 1.9368 - val_accuracy: 0.3010\n",
            "Epoch 43/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9189 - accuracy: 0.3176 - val_loss: 1.9198 - val_accuracy: 0.3155\n",
            "Epoch 44/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.9143 - accuracy: 0.3196 - val_loss: 1.9344 - val_accuracy: 0.3145\n",
            "Epoch 45/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.9099 - accuracy: 0.3225 - val_loss: 1.9501 - val_accuracy: 0.2965\n",
            "Epoch 46/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9084 - accuracy: 0.3232 - val_loss: 1.9645 - val_accuracy: 0.2915\n",
            "Epoch 47/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9034 - accuracy: 0.3268 - val_loss: 1.9327 - val_accuracy: 0.3080\n",
            "Epoch 48/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.9000 - accuracy: 0.3266 - val_loss: 1.9149 - val_accuracy: 0.3195\n",
            "Epoch 49/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8965 - accuracy: 0.3280 - val_loss: 1.9045 - val_accuracy: 0.3180\n",
            "Epoch 50/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8925 - accuracy: 0.3250 - val_loss: 1.9003 - val_accuracy: 0.3185\n",
            "Epoch 51/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8894 - accuracy: 0.3307 - val_loss: 1.9456 - val_accuracy: 0.3025\n",
            "Epoch 52/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8871 - accuracy: 0.3289 - val_loss: 1.8999 - val_accuracy: 0.3205\n",
            "Epoch 53/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8832 - accuracy: 0.3318 - val_loss: 1.8960 - val_accuracy: 0.3260\n",
            "Epoch 54/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8804 - accuracy: 0.3348 - val_loss: 1.9040 - val_accuracy: 0.3190\n",
            "Epoch 55/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8764 - accuracy: 0.3340 - val_loss: 1.8907 - val_accuracy: 0.3245\n",
            "Epoch 56/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8734 - accuracy: 0.3339 - val_loss: 1.9053 - val_accuracy: 0.3225\n",
            "Epoch 57/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8713 - accuracy: 0.3311 - val_loss: 1.8837 - val_accuracy: 0.3245\n",
            "Epoch 58/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8699 - accuracy: 0.3370 - val_loss: 1.8856 - val_accuracy: 0.3205\n",
            "Epoch 59/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8648 - accuracy: 0.3367 - val_loss: 1.8946 - val_accuracy: 0.3095\n",
            "Epoch 60/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8632 - accuracy: 0.3373 - val_loss: 1.8746 - val_accuracy: 0.3280\n",
            "Epoch 61/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8589 - accuracy: 0.3408 - val_loss: 1.8807 - val_accuracy: 0.3360\n",
            "Epoch 62/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8564 - accuracy: 0.3417 - val_loss: 1.8830 - val_accuracy: 0.3275\n",
            "Epoch 63/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8537 - accuracy: 0.3409 - val_loss: 1.8894 - val_accuracy: 0.3135\n",
            "Epoch 64/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8517 - accuracy: 0.3426 - val_loss: 1.8874 - val_accuracy: 0.3180\n",
            "Epoch 65/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8492 - accuracy: 0.3430 - val_loss: 1.8595 - val_accuracy: 0.3255\n",
            "Epoch 66/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8453 - accuracy: 0.3433 - val_loss: 1.8633 - val_accuracy: 0.3250\n",
            "Epoch 67/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8423 - accuracy: 0.3473 - val_loss: 1.8615 - val_accuracy: 0.3260\n",
            "Epoch 68/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8417 - accuracy: 0.3465 - val_loss: 1.8533 - val_accuracy: 0.3405\n",
            "Epoch 69/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8372 - accuracy: 0.3486 - val_loss: 1.8897 - val_accuracy: 0.3285\n",
            "Epoch 70/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8371 - accuracy: 0.3484 - val_loss: 1.8530 - val_accuracy: 0.3350\n",
            "Epoch 71/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8341 - accuracy: 0.3494 - val_loss: 1.8647 - val_accuracy: 0.3295\n",
            "Epoch 72/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8298 - accuracy: 0.3499 - val_loss: 1.8520 - val_accuracy: 0.3415\n",
            "Epoch 73/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8276 - accuracy: 0.3504 - val_loss: 1.8867 - val_accuracy: 0.3160\n",
            "Epoch 74/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8253 - accuracy: 0.3528 - val_loss: 1.9802 - val_accuracy: 0.2740\n",
            "Epoch 75/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8259 - accuracy: 0.3500 - val_loss: 1.9063 - val_accuracy: 0.3145\n",
            "Epoch 76/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8209 - accuracy: 0.3557 - val_loss: 1.8353 - val_accuracy: 0.3520\n",
            "Epoch 77/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8166 - accuracy: 0.3547 - val_loss: 1.8375 - val_accuracy: 0.3505\n",
            "Epoch 78/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8140 - accuracy: 0.3565 - val_loss: 1.8666 - val_accuracy: 0.3220\n",
            "Epoch 79/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8111 - accuracy: 0.3606 - val_loss: 1.8414 - val_accuracy: 0.3345\n",
            "Epoch 80/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8092 - accuracy: 0.3587 - val_loss: 1.8279 - val_accuracy: 0.3505\n",
            "Epoch 81/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.8064 - accuracy: 0.3593 - val_loss: 1.8567 - val_accuracy: 0.3385\n",
            "Epoch 82/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8048 - accuracy: 0.3593 - val_loss: 1.8747 - val_accuracy: 0.3275\n",
            "Epoch 83/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.8013 - accuracy: 0.3652 - val_loss: 1.8402 - val_accuracy: 0.3370\n",
            "Epoch 84/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7977 - accuracy: 0.3655 - val_loss: 1.8381 - val_accuracy: 0.3440\n",
            "Epoch 85/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.7962 - accuracy: 0.3659 - val_loss: 1.8310 - val_accuracy: 0.3425\n",
            "Epoch 86/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7948 - accuracy: 0.3671 - val_loss: 1.8328 - val_accuracy: 0.3475\n",
            "Epoch 87/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7903 - accuracy: 0.3679 - val_loss: 1.8119 - val_accuracy: 0.3550\n",
            "Epoch 88/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7895 - accuracy: 0.3684 - val_loss: 1.8626 - val_accuracy: 0.3395\n",
            "Epoch 89/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7869 - accuracy: 0.3651 - val_loss: 1.8235 - val_accuracy: 0.3475\n",
            "Epoch 90/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7821 - accuracy: 0.3663 - val_loss: 1.8281 - val_accuracy: 0.3385\n",
            "Epoch 91/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7799 - accuracy: 0.3651 - val_loss: 1.8096 - val_accuracy: 0.3670\n",
            "Epoch 92/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7790 - accuracy: 0.3693 - val_loss: 1.7953 - val_accuracy: 0.3650\n",
            "Epoch 93/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7765 - accuracy: 0.3724 - val_loss: 1.8022 - val_accuracy: 0.3615\n",
            "Epoch 94/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7732 - accuracy: 0.3734 - val_loss: 1.8176 - val_accuracy: 0.3345\n",
            "Epoch 95/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7714 - accuracy: 0.3699 - val_loss: 1.7809 - val_accuracy: 0.3715\n",
            "Epoch 96/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7687 - accuracy: 0.3735 - val_loss: 1.7889 - val_accuracy: 0.3680\n",
            "Epoch 97/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7639 - accuracy: 0.3745 - val_loss: 1.8041 - val_accuracy: 0.3600\n",
            "Epoch 98/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7615 - accuracy: 0.3771 - val_loss: 1.7841 - val_accuracy: 0.3780\n",
            "Epoch 99/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7589 - accuracy: 0.3815 - val_loss: 1.7946 - val_accuracy: 0.3640\n",
            "Epoch 100/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7591 - accuracy: 0.3767 - val_loss: 1.7883 - val_accuracy: 0.3655\n",
            "Epoch 101/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7545 - accuracy: 0.3790 - val_loss: 1.7885 - val_accuracy: 0.3630\n",
            "Epoch 102/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7522 - accuracy: 0.3823 - val_loss: 1.8021 - val_accuracy: 0.3585\n",
            "Epoch 103/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7509 - accuracy: 0.3831 - val_loss: 1.8193 - val_accuracy: 0.3480\n",
            "Epoch 104/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7484 - accuracy: 0.3819 - val_loss: 1.7663 - val_accuracy: 0.3765\n",
            "Epoch 105/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7433 - accuracy: 0.3835 - val_loss: 1.7688 - val_accuracy: 0.3860\n",
            "Epoch 106/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7425 - accuracy: 0.3841 - val_loss: 1.8152 - val_accuracy: 0.3530\n",
            "Epoch 107/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.7382 - accuracy: 0.3847 - val_loss: 1.8007 - val_accuracy: 0.3625\n",
            "Epoch 108/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7367 - accuracy: 0.3866 - val_loss: 1.7929 - val_accuracy: 0.3550\n",
            "Epoch 109/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7369 - accuracy: 0.3862 - val_loss: 1.7758 - val_accuracy: 0.3650\n",
            "Epoch 110/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7340 - accuracy: 0.3877 - val_loss: 1.7740 - val_accuracy: 0.3665\n",
            "Epoch 111/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.7319 - accuracy: 0.3893 - val_loss: 1.7765 - val_accuracy: 0.3800\n",
            "Epoch 112/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.7272 - accuracy: 0.3902 - val_loss: 1.7655 - val_accuracy: 0.3625\n",
            "Epoch 113/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7252 - accuracy: 0.3899 - val_loss: 1.7536 - val_accuracy: 0.3830\n",
            "Epoch 114/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.7233 - accuracy: 0.3928 - val_loss: 1.7598 - val_accuracy: 0.3690\n",
            "Epoch 115/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7204 - accuracy: 0.3935 - val_loss: 1.7700 - val_accuracy: 0.3650\n",
            "Epoch 116/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7175 - accuracy: 0.3955 - val_loss: 1.7476 - val_accuracy: 0.4040\n",
            "Epoch 117/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7142 - accuracy: 0.3938 - val_loss: 1.7445 - val_accuracy: 0.3935\n",
            "Epoch 118/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.7123 - accuracy: 0.3944 - val_loss: 1.7395 - val_accuracy: 0.3810\n",
            "Epoch 119/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7100 - accuracy: 0.3993 - val_loss: 1.7327 - val_accuracy: 0.3985\n",
            "Epoch 120/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7085 - accuracy: 0.3970 - val_loss: 1.7372 - val_accuracy: 0.3930\n",
            "Epoch 121/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7065 - accuracy: 0.3958 - val_loss: 1.7300 - val_accuracy: 0.3990\n",
            "Epoch 122/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7038 - accuracy: 0.3992 - val_loss: 1.7585 - val_accuracy: 0.3830\n",
            "Epoch 123/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7013 - accuracy: 0.4007 - val_loss: 1.8315 - val_accuracy: 0.3530\n",
            "Epoch 124/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.7004 - accuracy: 0.4003 - val_loss: 1.7590 - val_accuracy: 0.3675\n",
            "Epoch 125/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.6980 - accuracy: 0.4010 - val_loss: 1.7239 - val_accuracy: 0.3850\n",
            "Epoch 126/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6951 - accuracy: 0.4010 - val_loss: 1.7190 - val_accuracy: 0.3820\n",
            "Epoch 127/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6920 - accuracy: 0.4046 - val_loss: 1.7151 - val_accuracy: 0.3940\n",
            "Epoch 128/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6891 - accuracy: 0.4015 - val_loss: 1.7450 - val_accuracy: 0.3885\n",
            "Epoch 129/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6853 - accuracy: 0.4076 - val_loss: 1.7240 - val_accuracy: 0.3940\n",
            "Epoch 130/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.6856 - accuracy: 0.4048 - val_loss: 1.7794 - val_accuracy: 0.3815\n",
            "Epoch 131/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6857 - accuracy: 0.4069 - val_loss: 1.7658 - val_accuracy: 0.3680\n",
            "Epoch 132/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6822 - accuracy: 0.4083 - val_loss: 1.7881 - val_accuracy: 0.3690\n",
            "Epoch 133/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6819 - accuracy: 0.4084 - val_loss: 1.7107 - val_accuracy: 0.4080\n",
            "Epoch 134/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.6778 - accuracy: 0.4093 - val_loss: 1.7962 - val_accuracy: 0.3560\n",
            "Epoch 135/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6751 - accuracy: 0.4114 - val_loss: 1.7036 - val_accuracy: 0.4050\n",
            "Epoch 136/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6737 - accuracy: 0.4129 - val_loss: 1.7010 - val_accuracy: 0.4090\n",
            "Epoch 137/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6724 - accuracy: 0.4036 - val_loss: 1.7127 - val_accuracy: 0.3780\n",
            "Epoch 138/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6710 - accuracy: 0.4079 - val_loss: 1.6927 - val_accuracy: 0.4155\n",
            "Epoch 139/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6674 - accuracy: 0.4138 - val_loss: 1.7642 - val_accuracy: 0.3730\n",
            "Epoch 140/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6674 - accuracy: 0.4111 - val_loss: 1.7032 - val_accuracy: 0.4025\n",
            "Epoch 141/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6636 - accuracy: 0.4118 - val_loss: 1.6905 - val_accuracy: 0.4120\n",
            "Epoch 142/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.6622 - accuracy: 0.4177 - val_loss: 1.7815 - val_accuracy: 0.3710\n",
            "Epoch 143/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6610 - accuracy: 0.4116 - val_loss: 1.7065 - val_accuracy: 0.4000\n",
            "Epoch 144/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6597 - accuracy: 0.4163 - val_loss: 1.7939 - val_accuracy: 0.3670\n",
            "Epoch 145/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6577 - accuracy: 0.4184 - val_loss: 1.7167 - val_accuracy: 0.3865\n",
            "Epoch 146/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6545 - accuracy: 0.4173 - val_loss: 1.6968 - val_accuracy: 0.3995\n",
            "Epoch 147/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6559 - accuracy: 0.4213 - val_loss: 1.7592 - val_accuracy: 0.3695\n",
            "Epoch 148/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6524 - accuracy: 0.4185 - val_loss: 1.7306 - val_accuracy: 0.3750\n",
            "Epoch 149/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6507 - accuracy: 0.4208 - val_loss: 1.7243 - val_accuracy: 0.3965\n",
            "Epoch 150/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6498 - accuracy: 0.4156 - val_loss: 1.6941 - val_accuracy: 0.3920\n",
            "Epoch 151/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6467 - accuracy: 0.4223 - val_loss: 1.7712 - val_accuracy: 0.3740\n",
            "Epoch 152/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6470 - accuracy: 0.4205 - val_loss: 1.6824 - val_accuracy: 0.4040\n",
            "Epoch 153/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.6413 - accuracy: 0.4207 - val_loss: 1.7573 - val_accuracy: 0.3865\n",
            "Epoch 154/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6416 - accuracy: 0.4215 - val_loss: 1.7537 - val_accuracy: 0.3825\n",
            "Epoch 155/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6380 - accuracy: 0.4252 - val_loss: 1.6599 - val_accuracy: 0.4115\n",
            "Epoch 156/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6378 - accuracy: 0.4246 - val_loss: 1.6939 - val_accuracy: 0.4075\n",
            "Epoch 157/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6359 - accuracy: 0.4266 - val_loss: 1.6752 - val_accuracy: 0.4180\n",
            "Epoch 158/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.6348 - accuracy: 0.4283 - val_loss: 1.6532 - val_accuracy: 0.4215\n",
            "Epoch 159/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6305 - accuracy: 0.4291 - val_loss: 1.7619 - val_accuracy: 0.3850\n",
            "Epoch 160/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6321 - accuracy: 0.4244 - val_loss: 1.6935 - val_accuracy: 0.3980\n",
            "Epoch 161/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6304 - accuracy: 0.4300 - val_loss: 1.6958 - val_accuracy: 0.3985\n",
            "Epoch 162/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6257 - accuracy: 0.4258 - val_loss: 1.6872 - val_accuracy: 0.4095\n",
            "Epoch 163/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6229 - accuracy: 0.4307 - val_loss: 1.6719 - val_accuracy: 0.4285\n",
            "Epoch 164/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6241 - accuracy: 0.4289 - val_loss: 1.8254 - val_accuracy: 0.3455\n",
            "Epoch 165/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6223 - accuracy: 0.4280 - val_loss: 1.6715 - val_accuracy: 0.4025\n",
            "Epoch 166/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6178 - accuracy: 0.4330 - val_loss: 1.6881 - val_accuracy: 0.4055\n",
            "Epoch 167/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6189 - accuracy: 0.4298 - val_loss: 1.6993 - val_accuracy: 0.4040\n",
            "Epoch 168/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6161 - accuracy: 0.4327 - val_loss: 1.7443 - val_accuracy: 0.3700\n",
            "Epoch 169/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6126 - accuracy: 0.4352 - val_loss: 1.7086 - val_accuracy: 0.3910\n",
            "Epoch 170/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6130 - accuracy: 0.4338 - val_loss: 1.6779 - val_accuracy: 0.4170\n",
            "Epoch 171/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6101 - accuracy: 0.4367 - val_loss: 1.6542 - val_accuracy: 0.4315\n",
            "Epoch 172/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6075 - accuracy: 0.4352 - val_loss: 1.6530 - val_accuracy: 0.4245\n",
            "Epoch 173/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6066 - accuracy: 0.4377 - val_loss: 1.7080 - val_accuracy: 0.3930\n",
            "Epoch 174/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6059 - accuracy: 0.4383 - val_loss: 1.6386 - val_accuracy: 0.4280\n",
            "Epoch 175/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6050 - accuracy: 0.4389 - val_loss: 1.7632 - val_accuracy: 0.3750\n",
            "Epoch 176/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6080 - accuracy: 0.4380 - val_loss: 1.6460 - val_accuracy: 0.4250\n",
            "Epoch 177/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5995 - accuracy: 0.4384 - val_loss: 1.6733 - val_accuracy: 0.3990\n",
            "Epoch 178/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5990 - accuracy: 0.4427 - val_loss: 1.6856 - val_accuracy: 0.3980\n",
            "Epoch 179/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.6001 - accuracy: 0.4401 - val_loss: 1.7804 - val_accuracy: 0.3705\n",
            "Epoch 180/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5970 - accuracy: 0.4420 - val_loss: 1.6536 - val_accuracy: 0.3970\n",
            "Epoch 181/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5931 - accuracy: 0.4424 - val_loss: 1.6681 - val_accuracy: 0.4155\n",
            "Epoch 182/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5939 - accuracy: 0.4409 - val_loss: 1.6844 - val_accuracy: 0.3910\n",
            "Epoch 183/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5903 - accuracy: 0.4418 - val_loss: 1.6923 - val_accuracy: 0.3930\n",
            "Epoch 184/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5933 - accuracy: 0.4382 - val_loss: 1.6423 - val_accuracy: 0.4135\n",
            "Epoch 185/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5871 - accuracy: 0.4435 - val_loss: 1.6397 - val_accuracy: 0.4410\n",
            "Epoch 186/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5854 - accuracy: 0.4456 - val_loss: 1.8670 - val_accuracy: 0.3420\n",
            "Epoch 187/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5897 - accuracy: 0.4447 - val_loss: 1.6652 - val_accuracy: 0.4030\n",
            "Epoch 188/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5841 - accuracy: 0.4484 - val_loss: 1.7711 - val_accuracy: 0.3810\n",
            "Epoch 189/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5842 - accuracy: 0.4458 - val_loss: 1.8429 - val_accuracy: 0.3555\n",
            "Epoch 190/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5798 - accuracy: 0.4455 - val_loss: 1.6893 - val_accuracy: 0.4120\n",
            "Epoch 191/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5820 - accuracy: 0.4499 - val_loss: 1.8100 - val_accuracy: 0.3705\n",
            "Epoch 192/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5769 - accuracy: 0.4461 - val_loss: 1.6497 - val_accuracy: 0.4145\n",
            "Epoch 193/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5757 - accuracy: 0.4512 - val_loss: 1.7060 - val_accuracy: 0.3830\n",
            "Epoch 194/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5743 - accuracy: 0.4469 - val_loss: 1.8569 - val_accuracy: 0.3550\n",
            "Epoch 195/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5719 - accuracy: 0.4489 - val_loss: 1.6328 - val_accuracy: 0.4025\n",
            "Epoch 196/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.5714 - accuracy: 0.4491 - val_loss: 1.6647 - val_accuracy: 0.4065\n",
            "Epoch 197/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5665 - accuracy: 0.4488 - val_loss: 1.6304 - val_accuracy: 0.4175\n",
            "Epoch 198/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5673 - accuracy: 0.4529 - val_loss: 1.6286 - val_accuracy: 0.4325\n",
            "Epoch 199/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5642 - accuracy: 0.4514 - val_loss: 1.6799 - val_accuracy: 0.4120\n",
            "Epoch 200/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5643 - accuracy: 0.4526 - val_loss: 1.6065 - val_accuracy: 0.4365\n",
            "Epoch 201/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5593 - accuracy: 0.4555 - val_loss: 1.6142 - val_accuracy: 0.4375\n",
            "Epoch 202/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5610 - accuracy: 0.4569 - val_loss: 1.7502 - val_accuracy: 0.3645\n",
            "Epoch 203/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5611 - accuracy: 0.4552 - val_loss: 1.6095 - val_accuracy: 0.4490\n",
            "Epoch 204/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5542 - accuracy: 0.4558 - val_loss: 1.6841 - val_accuracy: 0.4140\n",
            "Epoch 205/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5578 - accuracy: 0.4592 - val_loss: 1.6541 - val_accuracy: 0.4155\n",
            "Epoch 206/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5543 - accuracy: 0.4566 - val_loss: 1.6881 - val_accuracy: 0.3915\n",
            "Epoch 207/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5565 - accuracy: 0.4564 - val_loss: 1.6916 - val_accuracy: 0.4075\n",
            "Epoch 208/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5495 - accuracy: 0.4597 - val_loss: 1.6066 - val_accuracy: 0.4385\n",
            "Epoch 209/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5499 - accuracy: 0.4544 - val_loss: 1.6246 - val_accuracy: 0.4305\n",
            "Epoch 210/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5473 - accuracy: 0.4557 - val_loss: 1.6956 - val_accuracy: 0.4045\n",
            "Epoch 211/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5498 - accuracy: 0.4614 - val_loss: 1.6255 - val_accuracy: 0.4300\n",
            "Epoch 212/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5413 - accuracy: 0.4613 - val_loss: 1.6046 - val_accuracy: 0.4330\n",
            "Epoch 213/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5412 - accuracy: 0.4612 - val_loss: 1.6556 - val_accuracy: 0.4150\n",
            "Epoch 214/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5426 - accuracy: 0.4633 - val_loss: 1.6369 - val_accuracy: 0.4185\n",
            "Epoch 215/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5412 - accuracy: 0.4632 - val_loss: 1.6678 - val_accuracy: 0.4170\n",
            "Epoch 216/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5384 - accuracy: 0.4655 - val_loss: 1.6562 - val_accuracy: 0.4125\n",
            "Epoch 217/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5400 - accuracy: 0.4621 - val_loss: 1.6340 - val_accuracy: 0.4265\n",
            "Epoch 218/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5356 - accuracy: 0.4639 - val_loss: 1.6019 - val_accuracy: 0.4555\n",
            "Epoch 219/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5316 - accuracy: 0.4617 - val_loss: 1.6890 - val_accuracy: 0.4020\n",
            "Epoch 220/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5359 - accuracy: 0.4609 - val_loss: 1.6111 - val_accuracy: 0.4335\n",
            "Epoch 221/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5318 - accuracy: 0.4658 - val_loss: 1.7471 - val_accuracy: 0.3915\n",
            "Epoch 222/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5342 - accuracy: 0.4673 - val_loss: 1.6048 - val_accuracy: 0.4250\n",
            "Epoch 223/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5317 - accuracy: 0.4615 - val_loss: 1.6279 - val_accuracy: 0.4135\n",
            "Epoch 224/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5283 - accuracy: 0.4637 - val_loss: 1.5901 - val_accuracy: 0.4385\n",
            "Epoch 225/1000\n",
            "79/79 [==============================] - 0s 4ms/step - loss: 1.5229 - accuracy: 0.4660 - val_loss: 1.6015 - val_accuracy: 0.4370\n",
            "Epoch 226/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5224 - accuracy: 0.4681 - val_loss: 1.5767 - val_accuracy: 0.4500\n",
            "Epoch 227/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5214 - accuracy: 0.4662 - val_loss: 1.6048 - val_accuracy: 0.4330\n",
            "Epoch 228/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5218 - accuracy: 0.4673 - val_loss: 1.7999 - val_accuracy: 0.3755\n",
            "Epoch 229/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5233 - accuracy: 0.4686 - val_loss: 2.0766 - val_accuracy: 0.3300\n",
            "Epoch 230/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5229 - accuracy: 0.4675 - val_loss: 1.5769 - val_accuracy: 0.4485\n",
            "Epoch 231/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5159 - accuracy: 0.4713 - val_loss: 1.6411 - val_accuracy: 0.4285\n",
            "Epoch 232/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5158 - accuracy: 0.4684 - val_loss: 1.6296 - val_accuracy: 0.4150\n",
            "Epoch 233/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5126 - accuracy: 0.4705 - val_loss: 1.7292 - val_accuracy: 0.3965\n",
            "Epoch 234/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5140 - accuracy: 0.4732 - val_loss: 1.6496 - val_accuracy: 0.4295\n",
            "Epoch 235/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5126 - accuracy: 0.4720 - val_loss: 1.7816 - val_accuracy: 0.3705\n",
            "Epoch 236/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5145 - accuracy: 0.4717 - val_loss: 1.5817 - val_accuracy: 0.4290\n",
            "Epoch 237/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5070 - accuracy: 0.4753 - val_loss: 1.6242 - val_accuracy: 0.4435\n",
            "Epoch 238/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5080 - accuracy: 0.4716 - val_loss: 1.6227 - val_accuracy: 0.4210\n",
            "Epoch 239/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5055 - accuracy: 0.4758 - val_loss: 1.5643 - val_accuracy: 0.4620\n",
            "Epoch 240/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5009 - accuracy: 0.4753 - val_loss: 1.9207 - val_accuracy: 0.3425\n",
            "Epoch 241/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5065 - accuracy: 0.4710 - val_loss: 1.6013 - val_accuracy: 0.4180\n",
            "Epoch 242/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.5023 - accuracy: 0.4744 - val_loss: 1.6944 - val_accuracy: 0.4005\n",
            "Epoch 243/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4999 - accuracy: 0.4776 - val_loss: 1.5689 - val_accuracy: 0.4580\n",
            "Epoch 244/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4998 - accuracy: 0.4741 - val_loss: 1.6620 - val_accuracy: 0.4330\n",
            "Epoch 245/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4982 - accuracy: 0.4793 - val_loss: 1.7080 - val_accuracy: 0.3995\n",
            "Epoch 246/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4993 - accuracy: 0.4745 - val_loss: 1.5547 - val_accuracy: 0.4530\n",
            "Epoch 247/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4957 - accuracy: 0.4811 - val_loss: 1.6127 - val_accuracy: 0.4285\n",
            "Epoch 248/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4960 - accuracy: 0.4769 - val_loss: 1.6668 - val_accuracy: 0.4025\n",
            "Epoch 249/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4945 - accuracy: 0.4763 - val_loss: 1.7447 - val_accuracy: 0.3950\n",
            "Epoch 250/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4944 - accuracy: 0.4817 - val_loss: 1.7573 - val_accuracy: 0.3830\n",
            "Epoch 251/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4917 - accuracy: 0.4813 - val_loss: 1.6820 - val_accuracy: 0.4075\n",
            "Epoch 252/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4877 - accuracy: 0.4810 - val_loss: 1.5885 - val_accuracy: 0.4365\n",
            "Epoch 253/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4830 - accuracy: 0.4800 - val_loss: 1.6025 - val_accuracy: 0.4375\n",
            "Epoch 254/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4868 - accuracy: 0.4825 - val_loss: 1.6150 - val_accuracy: 0.4295\n",
            "Epoch 255/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4848 - accuracy: 0.4801 - val_loss: 1.5569 - val_accuracy: 0.4515\n",
            "Epoch 256/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4840 - accuracy: 0.4833 - val_loss: 1.6043 - val_accuracy: 0.4320\n",
            "Epoch 257/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4813 - accuracy: 0.4821 - val_loss: 1.6280 - val_accuracy: 0.4340\n",
            "Epoch 258/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4813 - accuracy: 0.4838 - val_loss: 1.5848 - val_accuracy: 0.4575\n",
            "Epoch 259/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4789 - accuracy: 0.4858 - val_loss: 1.7545 - val_accuracy: 0.4010\n",
            "Epoch 260/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4814 - accuracy: 0.4823 - val_loss: 1.5589 - val_accuracy: 0.4565\n",
            "Epoch 261/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4775 - accuracy: 0.4828 - val_loss: 1.6074 - val_accuracy: 0.4345\n",
            "Epoch 262/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4747 - accuracy: 0.4837 - val_loss: 1.5344 - val_accuracy: 0.4650\n",
            "Epoch 263/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4755 - accuracy: 0.4848 - val_loss: 1.7092 - val_accuracy: 0.3985\n",
            "Epoch 264/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4722 - accuracy: 0.4881 - val_loss: 1.7107 - val_accuracy: 0.4110\n",
            "Epoch 265/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4724 - accuracy: 0.4880 - val_loss: 1.5792 - val_accuracy: 0.4595\n",
            "Epoch 266/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4696 - accuracy: 0.4905 - val_loss: 1.5493 - val_accuracy: 0.4575\n",
            "Epoch 267/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4656 - accuracy: 0.4908 - val_loss: 1.5641 - val_accuracy: 0.4570\n",
            "Epoch 268/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4677 - accuracy: 0.4869 - val_loss: 1.5732 - val_accuracy: 0.4555\n",
            "Epoch 269/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4643 - accuracy: 0.4893 - val_loss: 1.5978 - val_accuracy: 0.4275\n",
            "Epoch 270/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4638 - accuracy: 0.4878 - val_loss: 1.6000 - val_accuracy: 0.4320\n",
            "Epoch 271/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4651 - accuracy: 0.4897 - val_loss: 1.6307 - val_accuracy: 0.4230\n",
            "Epoch 272/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4629 - accuracy: 0.4902 - val_loss: 1.5400 - val_accuracy: 0.4725\n",
            "Epoch 273/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4617 - accuracy: 0.4943 - val_loss: 1.5699 - val_accuracy: 0.4385\n",
            "Epoch 274/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4593 - accuracy: 0.4908 - val_loss: 1.6042 - val_accuracy: 0.4270\n",
            "Epoch 275/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4572 - accuracy: 0.4955 - val_loss: 1.5864 - val_accuracy: 0.4500\n",
            "Epoch 276/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4560 - accuracy: 0.4909 - val_loss: 1.6310 - val_accuracy: 0.4215\n",
            "Epoch 277/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4542 - accuracy: 0.4920 - val_loss: 1.7296 - val_accuracy: 0.3940\n",
            "Epoch 278/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4567 - accuracy: 0.4924 - val_loss: 1.5650 - val_accuracy: 0.4465\n",
            "Epoch 279/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4514 - accuracy: 0.4916 - val_loss: 1.5842 - val_accuracy: 0.4435\n",
            "Epoch 280/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4501 - accuracy: 0.4949 - val_loss: 1.7300 - val_accuracy: 0.3910\n",
            "Epoch 281/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4482 - accuracy: 0.4964 - val_loss: 1.6650 - val_accuracy: 0.4150\n",
            "Epoch 282/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4513 - accuracy: 0.4913 - val_loss: 1.6660 - val_accuracy: 0.4105\n",
            "Epoch 283/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4489 - accuracy: 0.4929 - val_loss: 1.6871 - val_accuracy: 0.4025\n",
            "Epoch 284/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4475 - accuracy: 0.4932 - val_loss: 1.6267 - val_accuracy: 0.4285\n",
            "Epoch 285/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4469 - accuracy: 0.4957 - val_loss: 1.6830 - val_accuracy: 0.3975\n",
            "Epoch 286/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4465 - accuracy: 0.4972 - val_loss: 1.5238 - val_accuracy: 0.4715\n",
            "Epoch 287/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4415 - accuracy: 0.4996 - val_loss: 1.6502 - val_accuracy: 0.4145\n",
            "Epoch 288/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4457 - accuracy: 0.5004 - val_loss: 1.5461 - val_accuracy: 0.4640\n",
            "Epoch 289/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4379 - accuracy: 0.4988 - val_loss: 1.5361 - val_accuracy: 0.4620\n",
            "Epoch 290/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4383 - accuracy: 0.5005 - val_loss: 1.5471 - val_accuracy: 0.4705\n",
            "Epoch 291/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4378 - accuracy: 0.5025 - val_loss: 1.6598 - val_accuracy: 0.4225\n",
            "Epoch 292/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4350 - accuracy: 0.4995 - val_loss: 1.5391 - val_accuracy: 0.4590\n",
            "Epoch 293/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4347 - accuracy: 0.5035 - val_loss: 1.5528 - val_accuracy: 0.4675\n",
            "Epoch 294/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4356 - accuracy: 0.5021 - val_loss: 1.5445 - val_accuracy: 0.4655\n",
            "Epoch 295/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4336 - accuracy: 0.5046 - val_loss: 1.5871 - val_accuracy: 0.4445\n",
            "Epoch 296/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4317 - accuracy: 0.5050 - val_loss: 1.7205 - val_accuracy: 0.4045\n",
            "Epoch 297/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4375 - accuracy: 0.5028 - val_loss: 1.6109 - val_accuracy: 0.4330\n",
            "Epoch 298/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4254 - accuracy: 0.5067 - val_loss: 1.5301 - val_accuracy: 0.4710\n",
            "Epoch 299/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4265 - accuracy: 0.5063 - val_loss: 1.6229 - val_accuracy: 0.4235\n",
            "Epoch 300/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4296 - accuracy: 0.5055 - val_loss: 1.7756 - val_accuracy: 0.3855\n",
            "Epoch 301/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4293 - accuracy: 0.5013 - val_loss: 1.6200 - val_accuracy: 0.4340\n",
            "Epoch 302/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4266 - accuracy: 0.4993 - val_loss: 1.5039 - val_accuracy: 0.4850\n",
            "Epoch 303/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4266 - accuracy: 0.5034 - val_loss: 1.5379 - val_accuracy: 0.4645\n",
            "Epoch 304/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4223 - accuracy: 0.5069 - val_loss: 1.5681 - val_accuracy: 0.4460\n",
            "Epoch 305/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4214 - accuracy: 0.5052 - val_loss: 1.5157 - val_accuracy: 0.4790\n",
            "Epoch 306/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4196 - accuracy: 0.5044 - val_loss: 1.5796 - val_accuracy: 0.4375\n",
            "Epoch 307/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4164 - accuracy: 0.5077 - val_loss: 1.7474 - val_accuracy: 0.3925\n",
            "Epoch 308/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4221 - accuracy: 0.5059 - val_loss: 1.5800 - val_accuracy: 0.4460\n",
            "Epoch 309/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4198 - accuracy: 0.5054 - val_loss: 1.6440 - val_accuracy: 0.4295\n",
            "Epoch 310/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4167 - accuracy: 0.5071 - val_loss: 1.5602 - val_accuracy: 0.4570\n",
            "Epoch 311/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4160 - accuracy: 0.5065 - val_loss: 1.5712 - val_accuracy: 0.4550\n",
            "Epoch 312/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4160 - accuracy: 0.5084 - val_loss: 1.5216 - val_accuracy: 0.4690\n",
            "Epoch 313/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4130 - accuracy: 0.5064 - val_loss: 1.5884 - val_accuracy: 0.4585\n",
            "Epoch 314/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4120 - accuracy: 0.5106 - val_loss: 1.5649 - val_accuracy: 0.4505\n",
            "Epoch 315/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4105 - accuracy: 0.5125 - val_loss: 1.6377 - val_accuracy: 0.4315\n",
            "Epoch 316/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4093 - accuracy: 0.5105 - val_loss: 1.5581 - val_accuracy: 0.4540\n",
            "Epoch 317/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4097 - accuracy: 0.5124 - val_loss: 1.5993 - val_accuracy: 0.4340\n",
            "Epoch 318/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4069 - accuracy: 0.5106 - val_loss: 1.8144 - val_accuracy: 0.3690\n",
            "Epoch 319/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4122 - accuracy: 0.5112 - val_loss: 1.5076 - val_accuracy: 0.4715\n",
            "Epoch 320/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4024 - accuracy: 0.5143 - val_loss: 1.5314 - val_accuracy: 0.4810\n",
            "Epoch 321/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4057 - accuracy: 0.5123 - val_loss: 1.5261 - val_accuracy: 0.4655\n",
            "Epoch 322/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4018 - accuracy: 0.5155 - val_loss: 1.5836 - val_accuracy: 0.4370\n",
            "Epoch 323/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4029 - accuracy: 0.5147 - val_loss: 1.6210 - val_accuracy: 0.4330\n",
            "Epoch 324/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4018 - accuracy: 0.5150 - val_loss: 1.5582 - val_accuracy: 0.4470\n",
            "Epoch 325/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.4023 - accuracy: 0.5134 - val_loss: 1.5396 - val_accuracy: 0.4625\n",
            "Epoch 326/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3975 - accuracy: 0.5169 - val_loss: 1.6733 - val_accuracy: 0.4220\n",
            "Epoch 327/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3979 - accuracy: 0.5143 - val_loss: 1.5998 - val_accuracy: 0.4340\n",
            "Epoch 328/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3984 - accuracy: 0.5185 - val_loss: 1.6965 - val_accuracy: 0.4055\n",
            "Epoch 329/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3954 - accuracy: 0.5116 - val_loss: 1.6284 - val_accuracy: 0.4330\n",
            "Epoch 330/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3944 - accuracy: 0.5165 - val_loss: 1.5146 - val_accuracy: 0.4755\n",
            "Epoch 331/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3956 - accuracy: 0.5185 - val_loss: 1.5566 - val_accuracy: 0.4450\n",
            "Epoch 332/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3914 - accuracy: 0.5219 - val_loss: 1.4995 - val_accuracy: 0.4765\n",
            "Epoch 333/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3895 - accuracy: 0.5143 - val_loss: 1.6099 - val_accuracy: 0.4370\n",
            "Epoch 334/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3912 - accuracy: 0.5146 - val_loss: 1.5359 - val_accuracy: 0.4700\n",
            "Epoch 335/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3907 - accuracy: 0.5191 - val_loss: 1.5885 - val_accuracy: 0.4370\n",
            "Epoch 336/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3872 - accuracy: 0.5199 - val_loss: 1.5355 - val_accuracy: 0.4525\n",
            "Epoch 337/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3914 - accuracy: 0.5172 - val_loss: 1.5194 - val_accuracy: 0.4685\n",
            "Epoch 338/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3823 - accuracy: 0.5202 - val_loss: 1.6905 - val_accuracy: 0.4075\n",
            "Epoch 339/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3821 - accuracy: 0.5182 - val_loss: 1.6351 - val_accuracy: 0.4295\n",
            "Epoch 340/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3856 - accuracy: 0.5216 - val_loss: 1.7832 - val_accuracy: 0.3875\n",
            "Epoch 341/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3820 - accuracy: 0.5209 - val_loss: 1.6208 - val_accuracy: 0.4300\n",
            "Epoch 342/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3829 - accuracy: 0.5197 - val_loss: 1.6432 - val_accuracy: 0.4115\n",
            "Epoch 343/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3794 - accuracy: 0.5216 - val_loss: 1.5224 - val_accuracy: 0.4740\n",
            "Epoch 344/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3778 - accuracy: 0.5204 - val_loss: 1.8361 - val_accuracy: 0.3640\n",
            "Epoch 345/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3863 - accuracy: 0.5246 - val_loss: 1.4824 - val_accuracy: 0.4920\n",
            "Epoch 346/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3767 - accuracy: 0.5233 - val_loss: 1.5387 - val_accuracy: 0.4605\n",
            "Epoch 347/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3733 - accuracy: 0.5231 - val_loss: 1.5150 - val_accuracy: 0.4580\n",
            "Epoch 348/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3720 - accuracy: 0.5269 - val_loss: 1.5983 - val_accuracy: 0.4330\n",
            "Epoch 349/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3738 - accuracy: 0.5280 - val_loss: 1.6422 - val_accuracy: 0.4285\n",
            "Epoch 350/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3730 - accuracy: 0.5243 - val_loss: 1.7552 - val_accuracy: 0.4170\n",
            "Epoch 351/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3786 - accuracy: 0.5258 - val_loss: 1.4825 - val_accuracy: 0.4795\n",
            "Epoch 352/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3683 - accuracy: 0.5250 - val_loss: 1.4891 - val_accuracy: 0.4740\n",
            "Epoch 353/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3680 - accuracy: 0.5271 - val_loss: 1.4975 - val_accuracy: 0.4670\n",
            "Epoch 354/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3657 - accuracy: 0.5257 - val_loss: 1.7409 - val_accuracy: 0.3985\n",
            "Epoch 355/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3724 - accuracy: 0.5242 - val_loss: 1.5494 - val_accuracy: 0.4385\n",
            "Epoch 356/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3650 - accuracy: 0.5237 - val_loss: 1.5058 - val_accuracy: 0.4725\n",
            "Epoch 357/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3662 - accuracy: 0.5267 - val_loss: 1.5236 - val_accuracy: 0.4655\n",
            "Epoch 358/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3644 - accuracy: 0.5278 - val_loss: 1.6423 - val_accuracy: 0.4380\n",
            "Epoch 359/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3700 - accuracy: 0.5268 - val_loss: 1.5561 - val_accuracy: 0.4430\n",
            "Epoch 360/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3627 - accuracy: 0.5279 - val_loss: 1.4980 - val_accuracy: 0.4830\n",
            "Epoch 361/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3634 - accuracy: 0.5288 - val_loss: 1.5047 - val_accuracy: 0.4835\n",
            "Epoch 362/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3633 - accuracy: 0.5299 - val_loss: 1.5094 - val_accuracy: 0.4705\n",
            "Epoch 363/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3628 - accuracy: 0.5263 - val_loss: 1.5288 - val_accuracy: 0.4695\n",
            "Epoch 364/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3564 - accuracy: 0.5256 - val_loss: 1.7604 - val_accuracy: 0.3975\n",
            "Epoch 365/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3590 - accuracy: 0.5308 - val_loss: 1.4779 - val_accuracy: 0.4840\n",
            "Epoch 366/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3581 - accuracy: 0.5310 - val_loss: 1.4974 - val_accuracy: 0.4765\n",
            "Epoch 367/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3520 - accuracy: 0.5283 - val_loss: 1.5442 - val_accuracy: 0.4465\n",
            "Epoch 368/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3536 - accuracy: 0.5313 - val_loss: 1.5007 - val_accuracy: 0.4750\n",
            "Epoch 369/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3546 - accuracy: 0.5302 - val_loss: 1.4763 - val_accuracy: 0.4915\n",
            "Epoch 370/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3509 - accuracy: 0.5331 - val_loss: 1.5184 - val_accuracy: 0.4585\n",
            "Epoch 371/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3510 - accuracy: 0.5327 - val_loss: 1.5702 - val_accuracy: 0.4510\n",
            "Epoch 372/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3496 - accuracy: 0.5338 - val_loss: 1.5878 - val_accuracy: 0.4420\n",
            "Epoch 373/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3547 - accuracy: 0.5310 - val_loss: 1.5641 - val_accuracy: 0.4815\n",
            "Epoch 374/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3476 - accuracy: 0.5304 - val_loss: 1.9708 - val_accuracy: 0.3735\n",
            "Epoch 375/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3526 - accuracy: 0.5301 - val_loss: 1.5294 - val_accuracy: 0.4655\n",
            "Epoch 376/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3470 - accuracy: 0.5325 - val_loss: 1.4725 - val_accuracy: 0.4950\n",
            "Epoch 377/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3446 - accuracy: 0.5356 - val_loss: 1.5575 - val_accuracy: 0.4425\n",
            "Epoch 378/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3437 - accuracy: 0.5359 - val_loss: 1.5266 - val_accuracy: 0.4695\n",
            "Epoch 379/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3443 - accuracy: 0.5312 - val_loss: 1.5233 - val_accuracy: 0.4605\n",
            "Epoch 380/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3415 - accuracy: 0.5362 - val_loss: 1.4818 - val_accuracy: 0.4895\n",
            "Epoch 381/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3413 - accuracy: 0.5350 - val_loss: 1.4816 - val_accuracy: 0.4905\n",
            "Epoch 382/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3391 - accuracy: 0.5357 - val_loss: 1.5615 - val_accuracy: 0.4475\n",
            "Epoch 383/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3406 - accuracy: 0.5326 - val_loss: 1.7474 - val_accuracy: 0.4110\n",
            "Epoch 384/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3367 - accuracy: 0.5381 - val_loss: 1.5596 - val_accuracy: 0.4390\n",
            "Epoch 385/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3363 - accuracy: 0.5385 - val_loss: 1.5538 - val_accuracy: 0.4545\n",
            "Epoch 386/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3372 - accuracy: 0.5381 - val_loss: 1.5149 - val_accuracy: 0.4780\n",
            "Epoch 387/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3310 - accuracy: 0.5343 - val_loss: 1.5077 - val_accuracy: 0.4870\n",
            "Epoch 388/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3309 - accuracy: 0.5387 - val_loss: 1.4899 - val_accuracy: 0.4720\n",
            "Epoch 389/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3312 - accuracy: 0.5347 - val_loss: 1.5052 - val_accuracy: 0.4830\n",
            "Epoch 390/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3297 - accuracy: 0.5397 - val_loss: 1.5658 - val_accuracy: 0.4515\n",
            "Epoch 391/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3327 - accuracy: 0.5408 - val_loss: 1.4935 - val_accuracy: 0.4775\n",
            "Epoch 392/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3276 - accuracy: 0.5414 - val_loss: 1.5020 - val_accuracy: 0.4760\n",
            "Epoch 393/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3283 - accuracy: 0.5397 - val_loss: 1.5116 - val_accuracy: 0.4860\n",
            "Epoch 394/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3331 - accuracy: 0.5387 - val_loss: 1.4872 - val_accuracy: 0.4825\n",
            "Epoch 395/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3249 - accuracy: 0.5432 - val_loss: 1.4888 - val_accuracy: 0.4830\n",
            "Epoch 396/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3264 - accuracy: 0.5428 - val_loss: 1.7417 - val_accuracy: 0.4260\n",
            "Epoch 397/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3271 - accuracy: 0.5396 - val_loss: 1.6015 - val_accuracy: 0.4505\n",
            "Epoch 398/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3295 - accuracy: 0.5403 - val_loss: 1.6356 - val_accuracy: 0.4280\n",
            "Epoch 399/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3241 - accuracy: 0.5410 - val_loss: 1.6239 - val_accuracy: 0.4340\n",
            "Epoch 400/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3245 - accuracy: 0.5385 - val_loss: 1.4777 - val_accuracy: 0.4895\n",
            "Epoch 401/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3214 - accuracy: 0.5440 - val_loss: 1.8250 - val_accuracy: 0.3695\n",
            "Epoch 402/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3201 - accuracy: 0.5389 - val_loss: 1.4904 - val_accuracy: 0.4785\n",
            "Epoch 403/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3236 - accuracy: 0.5452 - val_loss: 1.5600 - val_accuracy: 0.4515\n",
            "Epoch 404/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3257 - accuracy: 0.5442 - val_loss: 1.7746 - val_accuracy: 0.3970\n",
            "Epoch 405/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3164 - accuracy: 0.5468 - val_loss: 1.4564 - val_accuracy: 0.4960\n",
            "Epoch 406/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3137 - accuracy: 0.5458 - val_loss: 1.5234 - val_accuracy: 0.4855\n",
            "Epoch 407/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3178 - accuracy: 0.5473 - val_loss: 1.4880 - val_accuracy: 0.4740\n",
            "Epoch 408/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3143 - accuracy: 0.5480 - val_loss: 1.4853 - val_accuracy: 0.4875\n",
            "Epoch 409/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3166 - accuracy: 0.5470 - val_loss: 1.5132 - val_accuracy: 0.4745\n",
            "Epoch 410/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3116 - accuracy: 0.5477 - val_loss: 1.6336 - val_accuracy: 0.4325\n",
            "Epoch 411/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3133 - accuracy: 0.5458 - val_loss: 1.4627 - val_accuracy: 0.5030\n",
            "Epoch 412/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3080 - accuracy: 0.5482 - val_loss: 1.4782 - val_accuracy: 0.4885\n",
            "Epoch 413/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3100 - accuracy: 0.5462 - val_loss: 1.5117 - val_accuracy: 0.4605\n",
            "Epoch 414/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3091 - accuracy: 0.5461 - val_loss: 1.6648 - val_accuracy: 0.4335\n",
            "Epoch 415/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3116 - accuracy: 0.5424 - val_loss: 1.6471 - val_accuracy: 0.4365\n",
            "Epoch 416/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3071 - accuracy: 0.5523 - val_loss: 1.5880 - val_accuracy: 0.4475\n",
            "Epoch 417/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3068 - accuracy: 0.5513 - val_loss: 1.4955 - val_accuracy: 0.4920\n",
            "Epoch 418/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3031 - accuracy: 0.5515 - val_loss: 1.4748 - val_accuracy: 0.4900\n",
            "Epoch 419/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2999 - accuracy: 0.5516 - val_loss: 1.4858 - val_accuracy: 0.4825\n",
            "Epoch 420/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3046 - accuracy: 0.5471 - val_loss: 1.4643 - val_accuracy: 0.4860\n",
            "Epoch 421/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2956 - accuracy: 0.5498 - val_loss: 1.4790 - val_accuracy: 0.4975\n",
            "Epoch 422/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2958 - accuracy: 0.5481 - val_loss: 1.4642 - val_accuracy: 0.4920\n",
            "Epoch 423/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2992 - accuracy: 0.5503 - val_loss: 1.6096 - val_accuracy: 0.4485\n",
            "Epoch 424/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3024 - accuracy: 0.5517 - val_loss: 1.4575 - val_accuracy: 0.4860\n",
            "Epoch 425/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.3034 - accuracy: 0.5500 - val_loss: 1.5819 - val_accuracy: 0.4630\n",
            "Epoch 426/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2980 - accuracy: 0.5514 - val_loss: 1.4695 - val_accuracy: 0.4805\n",
            "Epoch 427/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2941 - accuracy: 0.5539 - val_loss: 1.6466 - val_accuracy: 0.4380\n",
            "Epoch 428/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2929 - accuracy: 0.5494 - val_loss: 1.4713 - val_accuracy: 0.4875\n",
            "Epoch 429/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2956 - accuracy: 0.5512 - val_loss: 1.5981 - val_accuracy: 0.4315\n",
            "Epoch 430/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2939 - accuracy: 0.5508 - val_loss: 1.5266 - val_accuracy: 0.4695\n",
            "Epoch 431/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2977 - accuracy: 0.5527 - val_loss: 1.4366 - val_accuracy: 0.5025\n",
            "Epoch 432/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2919 - accuracy: 0.5529 - val_loss: 1.5353 - val_accuracy: 0.4585\n",
            "Epoch 433/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2898 - accuracy: 0.5556 - val_loss: 1.5429 - val_accuracy: 0.4660\n",
            "Epoch 434/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2938 - accuracy: 0.5540 - val_loss: 1.4761 - val_accuracy: 0.4915\n",
            "Epoch 435/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2900 - accuracy: 0.5534 - val_loss: 1.4528 - val_accuracy: 0.4975\n",
            "Epoch 436/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2891 - accuracy: 0.5588 - val_loss: 1.4653 - val_accuracy: 0.4880\n",
            "Epoch 437/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2850 - accuracy: 0.5562 - val_loss: 1.4441 - val_accuracy: 0.5035\n",
            "Epoch 438/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2814 - accuracy: 0.5567 - val_loss: 1.5093 - val_accuracy: 0.4655\n",
            "Epoch 439/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2885 - accuracy: 0.5534 - val_loss: 1.6696 - val_accuracy: 0.4190\n",
            "Epoch 440/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2879 - accuracy: 0.5599 - val_loss: 1.6276 - val_accuracy: 0.4385\n",
            "Epoch 441/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2838 - accuracy: 0.5548 - val_loss: 1.5008 - val_accuracy: 0.4700\n",
            "Epoch 442/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2818 - accuracy: 0.5613 - val_loss: 1.5459 - val_accuracy: 0.4640\n",
            "Epoch 443/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2804 - accuracy: 0.5572 - val_loss: 1.4675 - val_accuracy: 0.4925\n",
            "Epoch 444/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2798 - accuracy: 0.5600 - val_loss: 1.4461 - val_accuracy: 0.4880\n",
            "Epoch 445/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2810 - accuracy: 0.5562 - val_loss: 1.4580 - val_accuracy: 0.4985\n",
            "Epoch 446/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2744 - accuracy: 0.5570 - val_loss: 1.5049 - val_accuracy: 0.4890\n",
            "Epoch 447/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2747 - accuracy: 0.5603 - val_loss: 1.6918 - val_accuracy: 0.4295\n",
            "Epoch 448/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2802 - accuracy: 0.5571 - val_loss: 1.4644 - val_accuracy: 0.4865\n",
            "Epoch 449/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2737 - accuracy: 0.5615 - val_loss: 1.5541 - val_accuracy: 0.4640\n",
            "Epoch 450/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2736 - accuracy: 0.5607 - val_loss: 1.4486 - val_accuracy: 0.4825\n",
            "Epoch 451/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2739 - accuracy: 0.5614 - val_loss: 1.4831 - val_accuracy: 0.4795\n",
            "Epoch 452/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2730 - accuracy: 0.5604 - val_loss: 1.5364 - val_accuracy: 0.4685\n",
            "Epoch 453/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2749 - accuracy: 0.5597 - val_loss: 1.4912 - val_accuracy: 0.4810\n",
            "Epoch 454/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2720 - accuracy: 0.5600 - val_loss: 1.6364 - val_accuracy: 0.4485\n",
            "Epoch 455/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2744 - accuracy: 0.5601 - val_loss: 1.5531 - val_accuracy: 0.4600\n",
            "Epoch 456/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2689 - accuracy: 0.5614 - val_loss: 1.6657 - val_accuracy: 0.4130\n",
            "Epoch 457/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2703 - accuracy: 0.5629 - val_loss: 1.5097 - val_accuracy: 0.4660\n",
            "Epoch 458/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2675 - accuracy: 0.5601 - val_loss: 1.5005 - val_accuracy: 0.4910\n",
            "Epoch 459/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2624 - accuracy: 0.5625 - val_loss: 1.4632 - val_accuracy: 0.4980\n",
            "Epoch 460/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2609 - accuracy: 0.5645 - val_loss: 1.6139 - val_accuracy: 0.4380\n",
            "Epoch 461/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2707 - accuracy: 0.5608 - val_loss: 1.7491 - val_accuracy: 0.4040\n",
            "Epoch 462/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2645 - accuracy: 0.5660 - val_loss: 1.5665 - val_accuracy: 0.4600\n",
            "Epoch 463/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2596 - accuracy: 0.5617 - val_loss: 1.4451 - val_accuracy: 0.4880\n",
            "Epoch 464/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2589 - accuracy: 0.5654 - val_loss: 1.4741 - val_accuracy: 0.4915\n",
            "Epoch 465/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2608 - accuracy: 0.5627 - val_loss: 1.5454 - val_accuracy: 0.4585\n",
            "Epoch 466/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2639 - accuracy: 0.5634 - val_loss: 1.5182 - val_accuracy: 0.4710\n",
            "Epoch 467/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2629 - accuracy: 0.5629 - val_loss: 1.5788 - val_accuracy: 0.4535\n",
            "Epoch 468/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2570 - accuracy: 0.5631 - val_loss: 1.4772 - val_accuracy: 0.4900\n",
            "Epoch 469/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2644 - accuracy: 0.5650 - val_loss: 1.5360 - val_accuracy: 0.4770\n",
            "Epoch 470/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2591 - accuracy: 0.5654 - val_loss: 1.4755 - val_accuracy: 0.4875\n",
            "Epoch 471/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2554 - accuracy: 0.5668 - val_loss: 1.4799 - val_accuracy: 0.4800\n",
            "Epoch 472/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2546 - accuracy: 0.5632 - val_loss: 1.4446 - val_accuracy: 0.4865\n",
            "Epoch 473/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2494 - accuracy: 0.5703 - val_loss: 1.6465 - val_accuracy: 0.4340\n",
            "Epoch 474/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2521 - accuracy: 0.5687 - val_loss: 1.5302 - val_accuracy: 0.4855\n",
            "Epoch 475/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2522 - accuracy: 0.5700 - val_loss: 1.5169 - val_accuracy: 0.4570\n",
            "Epoch 476/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2518 - accuracy: 0.5707 - val_loss: 1.5938 - val_accuracy: 0.4435\n",
            "Epoch 477/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2497 - accuracy: 0.5680 - val_loss: 1.4735 - val_accuracy: 0.4865\n",
            "Epoch 478/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2467 - accuracy: 0.5677 - val_loss: 1.4486 - val_accuracy: 0.4970\n",
            "Epoch 479/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2522 - accuracy: 0.5679 - val_loss: 1.7165 - val_accuracy: 0.4170\n",
            "Epoch 480/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2502 - accuracy: 0.5688 - val_loss: 1.4744 - val_accuracy: 0.4830\n",
            "Epoch 481/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2471 - accuracy: 0.5698 - val_loss: 1.4433 - val_accuracy: 0.5020\n",
            "Epoch 482/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2455 - accuracy: 0.5695 - val_loss: 1.6090 - val_accuracy: 0.4545\n",
            "Epoch 483/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2467 - accuracy: 0.5689 - val_loss: 1.6179 - val_accuracy: 0.4390\n",
            "Epoch 484/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2451 - accuracy: 0.5691 - val_loss: 1.4530 - val_accuracy: 0.5000\n",
            "Epoch 485/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2408 - accuracy: 0.5711 - val_loss: 1.5340 - val_accuracy: 0.4595\n",
            "Epoch 486/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2398 - accuracy: 0.5735 - val_loss: 1.4667 - val_accuracy: 0.4835\n",
            "Epoch 487/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2405 - accuracy: 0.5712 - val_loss: 1.4724 - val_accuracy: 0.5055\n",
            "Epoch 488/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2372 - accuracy: 0.5760 - val_loss: 1.4603 - val_accuracy: 0.4905\n",
            "Epoch 489/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2328 - accuracy: 0.5748 - val_loss: 1.4659 - val_accuracy: 0.4880\n",
            "Epoch 490/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2413 - accuracy: 0.5725 - val_loss: 1.4460 - val_accuracy: 0.4850\n",
            "Epoch 491/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2370 - accuracy: 0.5749 - val_loss: 1.5472 - val_accuracy: 0.4455\n",
            "Epoch 492/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2380 - accuracy: 0.5706 - val_loss: 1.5051 - val_accuracy: 0.4715\n",
            "Epoch 493/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2347 - accuracy: 0.5722 - val_loss: 1.5382 - val_accuracy: 0.4625\n",
            "Epoch 494/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2339 - accuracy: 0.5737 - val_loss: 1.5361 - val_accuracy: 0.4600\n",
            "Epoch 495/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2348 - accuracy: 0.5772 - val_loss: 1.4460 - val_accuracy: 0.4915\n",
            "Epoch 496/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2330 - accuracy: 0.5740 - val_loss: 1.4331 - val_accuracy: 0.4980\n",
            "Epoch 497/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2268 - accuracy: 0.5758 - val_loss: 1.5418 - val_accuracy: 0.4600\n",
            "Epoch 498/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2302 - accuracy: 0.5743 - val_loss: 1.5286 - val_accuracy: 0.4775\n",
            "Epoch 499/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2288 - accuracy: 0.5773 - val_loss: 1.4483 - val_accuracy: 0.4945\n",
            "Epoch 500/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2272 - accuracy: 0.5790 - val_loss: 1.4716 - val_accuracy: 0.4840\n",
            "Epoch 501/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2296 - accuracy: 0.5769 - val_loss: 1.7038 - val_accuracy: 0.4155\n",
            "Epoch 502/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2309 - accuracy: 0.5740 - val_loss: 1.4481 - val_accuracy: 0.4960\n",
            "Epoch 503/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2259 - accuracy: 0.5748 - val_loss: 1.4980 - val_accuracy: 0.4725\n",
            "Epoch 504/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2204 - accuracy: 0.5768 - val_loss: 1.4682 - val_accuracy: 0.4910\n",
            "Epoch 505/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2228 - accuracy: 0.5752 - val_loss: 1.4405 - val_accuracy: 0.4920\n",
            "Epoch 506/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2229 - accuracy: 0.5793 - val_loss: 1.4644 - val_accuracy: 0.4815\n",
            "Epoch 507/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2228 - accuracy: 0.5732 - val_loss: 1.5415 - val_accuracy: 0.4705\n",
            "Epoch 508/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2252 - accuracy: 0.5786 - val_loss: 1.5030 - val_accuracy: 0.4890\n",
            "Epoch 509/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2222 - accuracy: 0.5762 - val_loss: 1.4699 - val_accuracy: 0.4965\n",
            "Epoch 510/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2297 - accuracy: 0.5737 - val_loss: 1.4791 - val_accuracy: 0.4790\n",
            "Epoch 511/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2187 - accuracy: 0.5790 - val_loss: 1.5085 - val_accuracy: 0.4680\n",
            "Epoch 512/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2152 - accuracy: 0.5793 - val_loss: 1.5215 - val_accuracy: 0.4715\n",
            "Epoch 513/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2184 - accuracy: 0.5790 - val_loss: 1.4555 - val_accuracy: 0.5015\n",
            "Epoch 514/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2159 - accuracy: 0.5774 - val_loss: 1.4367 - val_accuracy: 0.4980\n",
            "Epoch 515/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2112 - accuracy: 0.5813 - val_loss: 1.4877 - val_accuracy: 0.4955\n",
            "Epoch 516/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2128 - accuracy: 0.5802 - val_loss: 1.4698 - val_accuracy: 0.5005\n",
            "Epoch 517/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2078 - accuracy: 0.5863 - val_loss: 1.6561 - val_accuracy: 0.4285\n",
            "Epoch 518/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2174 - accuracy: 0.5789 - val_loss: 1.5234 - val_accuracy: 0.4600\n",
            "Epoch 519/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2043 - accuracy: 0.5844 - val_loss: 1.5066 - val_accuracy: 0.4910\n",
            "Epoch 520/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2138 - accuracy: 0.5801 - val_loss: 1.4849 - val_accuracy: 0.4790\n",
            "Epoch 521/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2094 - accuracy: 0.5799 - val_loss: 1.5715 - val_accuracy: 0.4590\n",
            "Epoch 522/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2157 - accuracy: 0.5820 - val_loss: 1.4923 - val_accuracy: 0.4845\n",
            "Epoch 523/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2127 - accuracy: 0.5835 - val_loss: 1.4549 - val_accuracy: 0.5040\n",
            "Epoch 524/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2049 - accuracy: 0.5839 - val_loss: 1.4242 - val_accuracy: 0.5020\n",
            "Epoch 525/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2082 - accuracy: 0.5836 - val_loss: 1.4499 - val_accuracy: 0.5005\n",
            "Epoch 526/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2073 - accuracy: 0.5800 - val_loss: 1.4490 - val_accuracy: 0.4865\n",
            "Epoch 527/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2066 - accuracy: 0.5820 - val_loss: 1.4469 - val_accuracy: 0.4940\n",
            "Epoch 528/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2010 - accuracy: 0.5877 - val_loss: 1.5413 - val_accuracy: 0.4785\n",
            "Epoch 529/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2026 - accuracy: 0.5846 - val_loss: 1.4720 - val_accuracy: 0.4960\n",
            "Epoch 530/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2018 - accuracy: 0.5856 - val_loss: 1.4511 - val_accuracy: 0.4945\n",
            "Epoch 531/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1982 - accuracy: 0.5880 - val_loss: 2.5055 - val_accuracy: 0.3245\n",
            "Epoch 532/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.2127 - accuracy: 0.5807 - val_loss: 1.4565 - val_accuracy: 0.4845\n",
            "Epoch 533/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1947 - accuracy: 0.5868 - val_loss: 1.5381 - val_accuracy: 0.4710\n",
            "Epoch 534/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1969 - accuracy: 0.5828 - val_loss: 1.5210 - val_accuracy: 0.4645\n",
            "Epoch 535/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1961 - accuracy: 0.5882 - val_loss: 1.4319 - val_accuracy: 0.4855\n",
            "Epoch 536/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1985 - accuracy: 0.5855 - val_loss: 1.5305 - val_accuracy: 0.4630\n",
            "Epoch 537/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1979 - accuracy: 0.5886 - val_loss: 1.4812 - val_accuracy: 0.4850\n",
            "Epoch 538/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1898 - accuracy: 0.5920 - val_loss: 1.5306 - val_accuracy: 0.4800\n",
            "Epoch 539/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1936 - accuracy: 0.5885 - val_loss: 1.5002 - val_accuracy: 0.4830\n",
            "Epoch 540/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1912 - accuracy: 0.5902 - val_loss: 1.4507 - val_accuracy: 0.4830\n",
            "Epoch 541/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1886 - accuracy: 0.5917 - val_loss: 1.4917 - val_accuracy: 0.4890\n",
            "Epoch 542/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1924 - accuracy: 0.5894 - val_loss: 1.4588 - val_accuracy: 0.4880\n",
            "Epoch 543/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1848 - accuracy: 0.5910 - val_loss: 1.5653 - val_accuracy: 0.4575\n",
            "Epoch 544/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1893 - accuracy: 0.5865 - val_loss: 1.5425 - val_accuracy: 0.4615\n",
            "Epoch 545/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1892 - accuracy: 0.5910 - val_loss: 1.5103 - val_accuracy: 0.4820\n",
            "Epoch 546/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1866 - accuracy: 0.5929 - val_loss: 1.4297 - val_accuracy: 0.5005\n",
            "Epoch 547/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1857 - accuracy: 0.5904 - val_loss: 1.7960 - val_accuracy: 0.4120\n",
            "Epoch 548/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1843 - accuracy: 0.5896 - val_loss: 1.4556 - val_accuracy: 0.4960\n",
            "Epoch 549/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1836 - accuracy: 0.5895 - val_loss: 1.7833 - val_accuracy: 0.4020\n",
            "Epoch 550/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1875 - accuracy: 0.5859 - val_loss: 1.5365 - val_accuracy: 0.4515\n",
            "Epoch 551/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1796 - accuracy: 0.5916 - val_loss: 1.4201 - val_accuracy: 0.4995\n",
            "Epoch 552/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1787 - accuracy: 0.5948 - val_loss: 1.5536 - val_accuracy: 0.4805\n",
            "Epoch 553/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1814 - accuracy: 0.5920 - val_loss: 1.4351 - val_accuracy: 0.5025\n",
            "Epoch 554/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1747 - accuracy: 0.5957 - val_loss: 1.5049 - val_accuracy: 0.4805\n",
            "Epoch 555/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1804 - accuracy: 0.5891 - val_loss: 1.5155 - val_accuracy: 0.4810\n",
            "Epoch 556/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1759 - accuracy: 0.5934 - val_loss: 1.7751 - val_accuracy: 0.4255\n",
            "Epoch 557/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1813 - accuracy: 0.5924 - val_loss: 1.5314 - val_accuracy: 0.4865\n",
            "Epoch 558/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1755 - accuracy: 0.5922 - val_loss: 1.5449 - val_accuracy: 0.4880\n",
            "Epoch 559/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1771 - accuracy: 0.5925 - val_loss: 1.4462 - val_accuracy: 0.5055\n",
            "Epoch 560/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1778 - accuracy: 0.5957 - val_loss: 1.5499 - val_accuracy: 0.4575\n",
            "Epoch 561/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1689 - accuracy: 0.5953 - val_loss: 1.5520 - val_accuracy: 0.4610\n",
            "Epoch 562/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1682 - accuracy: 0.5960 - val_loss: 1.4803 - val_accuracy: 0.4900\n",
            "Epoch 563/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1696 - accuracy: 0.5958 - val_loss: 1.4725 - val_accuracy: 0.4775\n",
            "Epoch 564/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1692 - accuracy: 0.5968 - val_loss: 1.4326 - val_accuracy: 0.5000\n",
            "Epoch 565/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1708 - accuracy: 0.5964 - val_loss: 1.5081 - val_accuracy: 0.4785\n",
            "Epoch 566/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1728 - accuracy: 0.5940 - val_loss: 1.4295 - val_accuracy: 0.4965\n",
            "Epoch 567/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1660 - accuracy: 0.6001 - val_loss: 1.4772 - val_accuracy: 0.4790\n",
            "Epoch 568/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1636 - accuracy: 0.5990 - val_loss: 1.6198 - val_accuracy: 0.4435\n",
            "Epoch 569/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1646 - accuracy: 0.5936 - val_loss: 1.4407 - val_accuracy: 0.5005\n",
            "Epoch 570/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1618 - accuracy: 0.6004 - val_loss: 1.5095 - val_accuracy: 0.4900\n",
            "Epoch 571/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1631 - accuracy: 0.5974 - val_loss: 1.4455 - val_accuracy: 0.4885\n",
            "Epoch 572/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1659 - accuracy: 0.5971 - val_loss: 1.5448 - val_accuracy: 0.4685\n",
            "Epoch 573/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1633 - accuracy: 0.6006 - val_loss: 1.4432 - val_accuracy: 0.5070\n",
            "Epoch 574/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1569 - accuracy: 0.6002 - val_loss: 1.4774 - val_accuracy: 0.4815\n",
            "Epoch 575/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1639 - accuracy: 0.5973 - val_loss: 1.4734 - val_accuracy: 0.4840\n",
            "Epoch 576/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1674 - accuracy: 0.5988 - val_loss: 1.6399 - val_accuracy: 0.4690\n",
            "Epoch 577/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1632 - accuracy: 0.5953 - val_loss: 1.4532 - val_accuracy: 0.4985\n",
            "Epoch 578/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1571 - accuracy: 0.6015 - val_loss: 1.4198 - val_accuracy: 0.5050\n",
            "Epoch 579/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1592 - accuracy: 0.5989 - val_loss: 1.7773 - val_accuracy: 0.4110\n",
            "Epoch 580/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1622 - accuracy: 0.5990 - val_loss: 1.4563 - val_accuracy: 0.4965\n",
            "Epoch 581/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1600 - accuracy: 0.6019 - val_loss: 1.4651 - val_accuracy: 0.4975\n",
            "Epoch 582/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1514 - accuracy: 0.6046 - val_loss: 1.5583 - val_accuracy: 0.4755\n",
            "Epoch 583/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1501 - accuracy: 0.6008 - val_loss: 1.4270 - val_accuracy: 0.5005\n",
            "Epoch 584/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1490 - accuracy: 0.6000 - val_loss: 1.4898 - val_accuracy: 0.4755\n",
            "Epoch 585/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1501 - accuracy: 0.6053 - val_loss: 1.4737 - val_accuracy: 0.4810\n",
            "Epoch 586/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1494 - accuracy: 0.6049 - val_loss: 1.4167 - val_accuracy: 0.5095\n",
            "Epoch 587/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1531 - accuracy: 0.6037 - val_loss: 1.4700 - val_accuracy: 0.4865\n",
            "Epoch 588/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1513 - accuracy: 0.6025 - val_loss: 2.0727 - val_accuracy: 0.3790\n",
            "Epoch 589/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1568 - accuracy: 0.6029 - val_loss: 1.4123 - val_accuracy: 0.5150\n",
            "Epoch 590/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1422 - accuracy: 0.6063 - val_loss: 1.4913 - val_accuracy: 0.4910\n",
            "Epoch 591/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1457 - accuracy: 0.6042 - val_loss: 1.5124 - val_accuracy: 0.4840\n",
            "Epoch 592/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1455 - accuracy: 0.6054 - val_loss: 1.4576 - val_accuracy: 0.4955\n",
            "Epoch 593/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1458 - accuracy: 0.6056 - val_loss: 1.4193 - val_accuracy: 0.5050\n",
            "Epoch 594/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1412 - accuracy: 0.6076 - val_loss: 1.4365 - val_accuracy: 0.4990\n",
            "Epoch 595/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1445 - accuracy: 0.6015 - val_loss: 1.5140 - val_accuracy: 0.4820\n",
            "Epoch 596/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1426 - accuracy: 0.6078 - val_loss: 1.7519 - val_accuracy: 0.4370\n",
            "Epoch 597/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1419 - accuracy: 0.6071 - val_loss: 1.4067 - val_accuracy: 0.5075\n",
            "Epoch 598/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1409 - accuracy: 0.6101 - val_loss: 1.4059 - val_accuracy: 0.5120\n",
            "Epoch 599/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1311 - accuracy: 0.6103 - val_loss: 1.4399 - val_accuracy: 0.4910\n",
            "Epoch 600/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1378 - accuracy: 0.6065 - val_loss: 1.5621 - val_accuracy: 0.4645\n",
            "Epoch 601/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1415 - accuracy: 0.6084 - val_loss: 1.4727 - val_accuracy: 0.5005\n",
            "Epoch 602/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1379 - accuracy: 0.6052 - val_loss: 1.5070 - val_accuracy: 0.4625\n",
            "Epoch 603/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1358 - accuracy: 0.6051 - val_loss: 1.4641 - val_accuracy: 0.4850\n",
            "Epoch 604/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1334 - accuracy: 0.6082 - val_loss: 1.4144 - val_accuracy: 0.5105\n",
            "Epoch 605/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1322 - accuracy: 0.6090 - val_loss: 1.6328 - val_accuracy: 0.4360\n",
            "Epoch 606/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1309 - accuracy: 0.6109 - val_loss: 1.5283 - val_accuracy: 0.4715\n",
            "Epoch 607/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1297 - accuracy: 0.6117 - val_loss: 1.5537 - val_accuracy: 0.4590\n",
            "Epoch 608/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1294 - accuracy: 0.6103 - val_loss: 1.4675 - val_accuracy: 0.4795\n",
            "Epoch 609/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1259 - accuracy: 0.6123 - val_loss: 1.5735 - val_accuracy: 0.4515\n",
            "Epoch 610/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1236 - accuracy: 0.6159 - val_loss: 1.5804 - val_accuracy: 0.4515\n",
            "Epoch 611/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1248 - accuracy: 0.6133 - val_loss: 1.5074 - val_accuracy: 0.4750\n",
            "Epoch 612/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.1254 - accuracy: 0.6100 - val_loss: 1.4929 - val_accuracy: 0.4895\n",
            "Epoch 613/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1280 - accuracy: 0.6130 - val_loss: 1.4990 - val_accuracy: 0.4940\n",
            "Epoch 614/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1241 - accuracy: 0.6136 - val_loss: 1.6765 - val_accuracy: 0.4455\n",
            "Epoch 615/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1249 - accuracy: 0.6104 - val_loss: 1.5409 - val_accuracy: 0.4680\n",
            "Epoch 616/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1226 - accuracy: 0.6143 - val_loss: 1.4810 - val_accuracy: 0.4885\n",
            "Epoch 617/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1241 - accuracy: 0.6115 - val_loss: 1.5805 - val_accuracy: 0.4610\n",
            "Epoch 618/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1245 - accuracy: 0.6106 - val_loss: 1.5833 - val_accuracy: 0.4605\n",
            "Epoch 619/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1239 - accuracy: 0.6123 - val_loss: 1.4786 - val_accuracy: 0.4805\n",
            "Epoch 620/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1198 - accuracy: 0.6172 - val_loss: 1.4325 - val_accuracy: 0.5000\n",
            "Epoch 621/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1171 - accuracy: 0.6165 - val_loss: 1.4177 - val_accuracy: 0.5015\n",
            "Epoch 622/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1167 - accuracy: 0.6106 - val_loss: 1.4147 - val_accuracy: 0.5070\n",
            "Epoch 623/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1141 - accuracy: 0.6131 - val_loss: 1.7036 - val_accuracy: 0.4400\n",
            "Epoch 624/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1190 - accuracy: 0.6130 - val_loss: 1.4904 - val_accuracy: 0.4820\n",
            "Epoch 625/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1142 - accuracy: 0.6141 - val_loss: 1.4687 - val_accuracy: 0.4890\n",
            "Epoch 626/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1109 - accuracy: 0.6182 - val_loss: 1.5119 - val_accuracy: 0.4750\n",
            "Epoch 627/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1111 - accuracy: 0.6200 - val_loss: 1.4616 - val_accuracy: 0.4910\n",
            "Epoch 628/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1101 - accuracy: 0.6155 - val_loss: 1.5090 - val_accuracy: 0.4625\n",
            "Epoch 629/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1157 - accuracy: 0.6151 - val_loss: 1.5402 - val_accuracy: 0.4780\n",
            "Epoch 630/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1121 - accuracy: 0.6182 - val_loss: 1.4879 - val_accuracy: 0.4915\n",
            "Epoch 631/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1101 - accuracy: 0.6164 - val_loss: 1.4298 - val_accuracy: 0.4875\n",
            "Epoch 632/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1061 - accuracy: 0.6215 - val_loss: 1.5185 - val_accuracy: 0.4685\n",
            "Epoch 633/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1045 - accuracy: 0.6199 - val_loss: 1.4551 - val_accuracy: 0.5030\n",
            "Epoch 634/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.1052 - accuracy: 0.6220 - val_loss: 1.5092 - val_accuracy: 0.4860\n",
            "Epoch 635/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1051 - accuracy: 0.6195 - val_loss: 1.4151 - val_accuracy: 0.5035\n",
            "Epoch 636/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1025 - accuracy: 0.6225 - val_loss: 1.5049 - val_accuracy: 0.4830\n",
            "Epoch 637/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.1108 - accuracy: 0.6145 - val_loss: 1.4436 - val_accuracy: 0.4955\n",
            "Epoch 638/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1058 - accuracy: 0.6180 - val_loss: 1.6194 - val_accuracy: 0.4655\n",
            "Epoch 639/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1088 - accuracy: 0.6205 - val_loss: 1.5358 - val_accuracy: 0.4665\n",
            "Epoch 640/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0995 - accuracy: 0.6226 - val_loss: 1.5092 - val_accuracy: 0.4700\n",
            "Epoch 641/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.1031 - accuracy: 0.6225 - val_loss: 1.4684 - val_accuracy: 0.5020\n",
            "Epoch 642/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0987 - accuracy: 0.6230 - val_loss: 1.4050 - val_accuracy: 0.5120\n",
            "Epoch 643/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.6244 - val_loss: 1.4154 - val_accuracy: 0.5150\n",
            "Epoch 644/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0957 - accuracy: 0.6249 - val_loss: 1.4573 - val_accuracy: 0.4880\n",
            "Epoch 645/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0990 - accuracy: 0.6206 - val_loss: 1.4512 - val_accuracy: 0.4990\n",
            "Epoch 646/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0944 - accuracy: 0.6220 - val_loss: 1.4922 - val_accuracy: 0.4890\n",
            "Epoch 647/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0917 - accuracy: 0.6280 - val_loss: 1.4199 - val_accuracy: 0.5110\n",
            "Epoch 648/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0941 - accuracy: 0.6227 - val_loss: 1.6991 - val_accuracy: 0.4185\n",
            "Epoch 649/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0986 - accuracy: 0.6237 - val_loss: 1.4917 - val_accuracy: 0.4850\n",
            "Epoch 650/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0957 - accuracy: 0.6225 - val_loss: 1.4652 - val_accuracy: 0.4995\n",
            "Epoch 651/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0872 - accuracy: 0.6261 - val_loss: 1.8980 - val_accuracy: 0.3970\n",
            "Epoch 652/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0981 - accuracy: 0.6232 - val_loss: 1.4306 - val_accuracy: 0.5050\n",
            "Epoch 653/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0818 - accuracy: 0.6308 - val_loss: 1.7530 - val_accuracy: 0.4420\n",
            "Epoch 654/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0943 - accuracy: 0.6194 - val_loss: 1.5126 - val_accuracy: 0.4735\n",
            "Epoch 655/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0848 - accuracy: 0.6286 - val_loss: 1.6902 - val_accuracy: 0.4355\n",
            "Epoch 656/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0872 - accuracy: 0.6267 - val_loss: 1.4208 - val_accuracy: 0.5120\n",
            "Epoch 657/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0899 - accuracy: 0.6223 - val_loss: 1.4547 - val_accuracy: 0.4980\n",
            "Epoch 658/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0826 - accuracy: 0.6256 - val_loss: 1.6125 - val_accuracy: 0.4600\n",
            "Epoch 659/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0855 - accuracy: 0.6259 - val_loss: 1.5025 - val_accuracy: 0.4765\n",
            "Epoch 660/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0835 - accuracy: 0.6257 - val_loss: 1.5785 - val_accuracy: 0.4545\n",
            "Epoch 661/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0811 - accuracy: 0.6268 - val_loss: 1.4215 - val_accuracy: 0.4980\n",
            "Epoch 662/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0772 - accuracy: 0.6300 - val_loss: 1.5349 - val_accuracy: 0.4670\n",
            "Epoch 663/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0746 - accuracy: 0.6275 - val_loss: 1.5334 - val_accuracy: 0.4615\n",
            "Epoch 664/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0761 - accuracy: 0.6302 - val_loss: 1.4522 - val_accuracy: 0.5060\n",
            "Epoch 665/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0712 - accuracy: 0.6344 - val_loss: 1.4505 - val_accuracy: 0.5005\n",
            "Epoch 666/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0758 - accuracy: 0.6301 - val_loss: 1.4103 - val_accuracy: 0.5145\n",
            "Epoch 667/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0783 - accuracy: 0.6305 - val_loss: 1.4900 - val_accuracy: 0.4780\n",
            "Epoch 668/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0759 - accuracy: 0.6295 - val_loss: 1.4756 - val_accuracy: 0.4850\n",
            "Epoch 669/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0774 - accuracy: 0.6307 - val_loss: 1.4859 - val_accuracy: 0.4985\n",
            "Epoch 670/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0723 - accuracy: 0.6335 - val_loss: 1.4175 - val_accuracy: 0.5080\n",
            "Epoch 671/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0721 - accuracy: 0.6298 - val_loss: 1.4452 - val_accuracy: 0.5060\n",
            "Epoch 672/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0758 - accuracy: 0.6315 - val_loss: 1.4458 - val_accuracy: 0.5055\n",
            "Epoch 673/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0702 - accuracy: 0.6340 - val_loss: 1.5153 - val_accuracy: 0.4880\n",
            "Epoch 674/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0741 - accuracy: 0.6305 - val_loss: 1.5055 - val_accuracy: 0.4730\n",
            "Epoch 675/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0664 - accuracy: 0.6338 - val_loss: 1.4886 - val_accuracy: 0.4875\n",
            "Epoch 676/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0659 - accuracy: 0.6318 - val_loss: 1.4359 - val_accuracy: 0.5085\n",
            "Epoch 677/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0647 - accuracy: 0.6335 - val_loss: 1.5223 - val_accuracy: 0.4965\n",
            "Epoch 678/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0605 - accuracy: 0.6380 - val_loss: 1.5427 - val_accuracy: 0.4700\n",
            "Epoch 679/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0633 - accuracy: 0.6333 - val_loss: 1.4968 - val_accuracy: 0.4815\n",
            "Epoch 680/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0627 - accuracy: 0.6346 - val_loss: 1.6432 - val_accuracy: 0.4410\n",
            "Epoch 681/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0628 - accuracy: 0.6339 - val_loss: 1.4183 - val_accuracy: 0.5040\n",
            "Epoch 682/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0591 - accuracy: 0.6361 - val_loss: 1.4890 - val_accuracy: 0.4895\n",
            "Epoch 683/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0651 - accuracy: 0.6370 - val_loss: 1.5831 - val_accuracy: 0.4605\n",
            "Epoch 684/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0597 - accuracy: 0.6388 - val_loss: 1.5278 - val_accuracy: 0.4730\n",
            "Epoch 685/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0559 - accuracy: 0.6379 - val_loss: 1.6748 - val_accuracy: 0.4420\n",
            "Epoch 686/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0611 - accuracy: 0.6349 - val_loss: 1.5659 - val_accuracy: 0.4795\n",
            "Epoch 687/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0553 - accuracy: 0.6386 - val_loss: 1.5218 - val_accuracy: 0.4995\n",
            "Epoch 688/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0623 - accuracy: 0.6348 - val_loss: 1.7325 - val_accuracy: 0.4265\n",
            "Epoch 689/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0553 - accuracy: 0.6373 - val_loss: 1.8858 - val_accuracy: 0.3870\n",
            "Epoch 690/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0554 - accuracy: 0.6411 - val_loss: 1.5190 - val_accuracy: 0.4835\n",
            "Epoch 691/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0560 - accuracy: 0.6393 - val_loss: 1.5020 - val_accuracy: 0.4740\n",
            "Epoch 692/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0506 - accuracy: 0.6356 - val_loss: 1.5199 - val_accuracy: 0.4840\n",
            "Epoch 693/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0519 - accuracy: 0.6355 - val_loss: 1.4336 - val_accuracy: 0.5100\n",
            "Epoch 694/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0475 - accuracy: 0.6365 - val_loss: 1.4590 - val_accuracy: 0.4935\n",
            "Epoch 695/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0517 - accuracy: 0.6357 - val_loss: 1.5027 - val_accuracy: 0.4680\n",
            "Epoch 696/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0439 - accuracy: 0.6428 - val_loss: 1.5344 - val_accuracy: 0.4805\n",
            "Epoch 697/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0526 - accuracy: 0.6394 - val_loss: 1.4933 - val_accuracy: 0.4835\n",
            "Epoch 698/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0488 - accuracy: 0.6390 - val_loss: 1.4798 - val_accuracy: 0.4990\n",
            "Epoch 699/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0458 - accuracy: 0.6431 - val_loss: 1.4194 - val_accuracy: 0.5095\n",
            "Epoch 700/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0450 - accuracy: 0.6386 - val_loss: 1.5954 - val_accuracy: 0.4545\n",
            "Epoch 701/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0464 - accuracy: 0.6433 - val_loss: 1.4751 - val_accuracy: 0.4885\n",
            "Epoch 702/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0401 - accuracy: 0.6415 - val_loss: 1.5267 - val_accuracy: 0.4750\n",
            "Epoch 703/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0456 - accuracy: 0.6409 - val_loss: 1.4139 - val_accuracy: 0.5085\n",
            "Epoch 704/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0376 - accuracy: 0.6424 - val_loss: 1.4413 - val_accuracy: 0.5050\n",
            "Epoch 705/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0421 - accuracy: 0.6410 - val_loss: 1.6061 - val_accuracy: 0.4365\n",
            "Epoch 706/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0386 - accuracy: 0.6444 - val_loss: 1.5847 - val_accuracy: 0.4615\n",
            "Epoch 707/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0393 - accuracy: 0.6448 - val_loss: 1.5647 - val_accuracy: 0.4710\n",
            "Epoch 708/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0383 - accuracy: 0.6447 - val_loss: 1.5335 - val_accuracy: 0.4700\n",
            "Epoch 709/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0342 - accuracy: 0.6428 - val_loss: 1.4638 - val_accuracy: 0.4950\n",
            "Epoch 710/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0323 - accuracy: 0.6449 - val_loss: 1.5821 - val_accuracy: 0.4745\n",
            "Epoch 711/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0267 - accuracy: 0.6451 - val_loss: 1.4830 - val_accuracy: 0.4875\n",
            "Epoch 712/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0361 - accuracy: 0.6460 - val_loss: 1.4281 - val_accuracy: 0.5070\n",
            "Epoch 713/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0320 - accuracy: 0.6458 - val_loss: 1.4959 - val_accuracy: 0.4795\n",
            "Epoch 714/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0315 - accuracy: 0.6479 - val_loss: 1.4852 - val_accuracy: 0.4905\n",
            "Epoch 715/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0279 - accuracy: 0.6473 - val_loss: 1.4611 - val_accuracy: 0.4920\n",
            "Epoch 716/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0299 - accuracy: 0.6477 - val_loss: 1.5189 - val_accuracy: 0.4850\n",
            "Epoch 717/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0244 - accuracy: 0.6512 - val_loss: 1.5418 - val_accuracy: 0.4650\n",
            "Epoch 718/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0300 - accuracy: 0.6434 - val_loss: 1.4470 - val_accuracy: 0.4970\n",
            "Epoch 719/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0253 - accuracy: 0.6460 - val_loss: 1.4411 - val_accuracy: 0.4965\n",
            "Epoch 720/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0261 - accuracy: 0.6479 - val_loss: 1.4403 - val_accuracy: 0.4895\n",
            "Epoch 721/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0212 - accuracy: 0.6515 - val_loss: 1.7304 - val_accuracy: 0.4240\n",
            "Epoch 722/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0235 - accuracy: 0.6507 - val_loss: 1.4567 - val_accuracy: 0.5055\n",
            "Epoch 723/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0203 - accuracy: 0.6525 - val_loss: 1.4531 - val_accuracy: 0.5100\n",
            "Epoch 724/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0242 - accuracy: 0.6488 - val_loss: 1.4410 - val_accuracy: 0.4990\n",
            "Epoch 725/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0170 - accuracy: 0.6482 - val_loss: 1.4882 - val_accuracy: 0.4890\n",
            "Epoch 726/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0233 - accuracy: 0.6462 - val_loss: 1.4608 - val_accuracy: 0.5030\n",
            "Epoch 727/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0138 - accuracy: 0.6519 - val_loss: 1.4339 - val_accuracy: 0.4930\n",
            "Epoch 728/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0191 - accuracy: 0.6506 - val_loss: 1.6608 - val_accuracy: 0.4625\n",
            "Epoch 729/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0192 - accuracy: 0.6500 - val_loss: 1.6651 - val_accuracy: 0.4670\n",
            "Epoch 730/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0180 - accuracy: 0.6550 - val_loss: 1.8570 - val_accuracy: 0.4310\n",
            "Epoch 731/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0200 - accuracy: 0.6491 - val_loss: 1.4890 - val_accuracy: 0.4855\n",
            "Epoch 732/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0142 - accuracy: 0.6538 - val_loss: 1.4099 - val_accuracy: 0.5140\n",
            "Epoch 733/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0123 - accuracy: 0.6534 - val_loss: 1.4979 - val_accuracy: 0.4930\n",
            "Epoch 734/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0128 - accuracy: 0.6553 - val_loss: 1.5819 - val_accuracy: 0.4815\n",
            "Epoch 735/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0224 - accuracy: 0.6443 - val_loss: 1.4889 - val_accuracy: 0.4995\n",
            "Epoch 736/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0084 - accuracy: 0.6567 - val_loss: 2.1288 - val_accuracy: 0.4005\n",
            "Epoch 737/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0195 - accuracy: 0.6509 - val_loss: 1.4437 - val_accuracy: 0.4995\n",
            "Epoch 738/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0127 - accuracy: 0.6525 - val_loss: 1.4650 - val_accuracy: 0.4880\n",
            "Epoch 739/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 1.0086 - accuracy: 0.6544 - val_loss: 1.6379 - val_accuracy: 0.4515\n",
            "Epoch 740/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0069 - accuracy: 0.6581 - val_loss: 1.4562 - val_accuracy: 0.4995\n",
            "Epoch 741/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0117 - accuracy: 0.6537 - val_loss: 1.4038 - val_accuracy: 0.5155\n",
            "Epoch 742/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0045 - accuracy: 0.6542 - val_loss: 1.4282 - val_accuracy: 0.5025\n",
            "Epoch 743/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0039 - accuracy: 0.6557 - val_loss: 1.6265 - val_accuracy: 0.4730\n",
            "Epoch 744/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0071 - accuracy: 0.6563 - val_loss: 1.5366 - val_accuracy: 0.4705\n",
            "Epoch 745/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9982 - accuracy: 0.6593 - val_loss: 1.4231 - val_accuracy: 0.5140\n",
            "Epoch 746/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0012 - accuracy: 0.6605 - val_loss: 1.4110 - val_accuracy: 0.5115\n",
            "Epoch 747/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0037 - accuracy: 0.6563 - val_loss: 1.7052 - val_accuracy: 0.4340\n",
            "Epoch 748/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0025 - accuracy: 0.6571 - val_loss: 1.4262 - val_accuracy: 0.5010\n",
            "Epoch 749/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9948 - accuracy: 0.6569 - val_loss: 1.4901 - val_accuracy: 0.4875\n",
            "Epoch 750/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9950 - accuracy: 0.6590 - val_loss: 1.4912 - val_accuracy: 0.4915\n",
            "Epoch 751/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9960 - accuracy: 0.6621 - val_loss: 1.5310 - val_accuracy: 0.4745\n",
            "Epoch 752/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9971 - accuracy: 0.6585 - val_loss: 1.4885 - val_accuracy: 0.4875\n",
            "Epoch 753/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9963 - accuracy: 0.6598 - val_loss: 1.5208 - val_accuracy: 0.4755\n",
            "Epoch 754/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9938 - accuracy: 0.6614 - val_loss: 1.4887 - val_accuracy: 0.4895\n",
            "Epoch 755/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 1.0002 - accuracy: 0.6572 - val_loss: 1.4112 - val_accuracy: 0.5130\n",
            "Epoch 756/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9919 - accuracy: 0.6616 - val_loss: 1.4648 - val_accuracy: 0.5095\n",
            "Epoch 757/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9892 - accuracy: 0.6637 - val_loss: 1.5342 - val_accuracy: 0.4930\n",
            "Epoch 758/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9885 - accuracy: 0.6600 - val_loss: 1.5090 - val_accuracy: 0.4975\n",
            "Epoch 759/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9947 - accuracy: 0.6569 - val_loss: 1.5308 - val_accuracy: 0.4845\n",
            "Epoch 760/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9836 - accuracy: 0.6655 - val_loss: 1.5520 - val_accuracy: 0.4780\n",
            "Epoch 761/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.9890 - accuracy: 0.6574 - val_loss: 1.4316 - val_accuracy: 0.5040\n",
            "Epoch 762/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9916 - accuracy: 0.6617 - val_loss: 1.5204 - val_accuracy: 0.4740\n",
            "Epoch 763/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9848 - accuracy: 0.6611 - val_loss: 1.8525 - val_accuracy: 0.4040\n",
            "Epoch 764/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9831 - accuracy: 0.6644 - val_loss: 1.4769 - val_accuracy: 0.5035\n",
            "Epoch 765/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9887 - accuracy: 0.6622 - val_loss: 1.5744 - val_accuracy: 0.4580\n",
            "Epoch 766/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9830 - accuracy: 0.6616 - val_loss: 1.5329 - val_accuracy: 0.4865\n",
            "Epoch 767/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9818 - accuracy: 0.6645 - val_loss: 1.4800 - val_accuracy: 0.4930\n",
            "Epoch 768/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9817 - accuracy: 0.6667 - val_loss: 1.5401 - val_accuracy: 0.4875\n",
            "Epoch 769/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9789 - accuracy: 0.6657 - val_loss: 1.4720 - val_accuracy: 0.4955\n",
            "Epoch 770/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9764 - accuracy: 0.6671 - val_loss: 1.5113 - val_accuracy: 0.4935\n",
            "Epoch 771/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9782 - accuracy: 0.6668 - val_loss: 1.4327 - val_accuracy: 0.5150\n",
            "Epoch 772/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9799 - accuracy: 0.6642 - val_loss: 1.5788 - val_accuracy: 0.4795\n",
            "Epoch 773/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.9789 - accuracy: 0.6666 - val_loss: 1.4718 - val_accuracy: 0.4820\n",
            "Epoch 774/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9720 - accuracy: 0.6676 - val_loss: 1.4157 - val_accuracy: 0.5140\n",
            "Epoch 775/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9732 - accuracy: 0.6711 - val_loss: 1.6174 - val_accuracy: 0.4780\n",
            "Epoch 776/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9879 - accuracy: 0.6673 - val_loss: 1.5334 - val_accuracy: 0.4930\n",
            "Epoch 777/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9744 - accuracy: 0.6689 - val_loss: 1.7155 - val_accuracy: 0.4390\n",
            "Epoch 778/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9717 - accuracy: 0.6686 - val_loss: 1.6354 - val_accuracy: 0.4600\n",
            "Epoch 779/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9743 - accuracy: 0.6634 - val_loss: 1.4259 - val_accuracy: 0.5060\n",
            "Epoch 780/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9685 - accuracy: 0.6714 - val_loss: 1.5600 - val_accuracy: 0.4825\n",
            "Epoch 781/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9691 - accuracy: 0.6705 - val_loss: 1.5055 - val_accuracy: 0.4980\n",
            "Epoch 782/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9724 - accuracy: 0.6708 - val_loss: 1.5134 - val_accuracy: 0.4960\n",
            "Epoch 783/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9699 - accuracy: 0.6686 - val_loss: 1.4747 - val_accuracy: 0.4995\n",
            "Epoch 784/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9661 - accuracy: 0.6672 - val_loss: 1.4333 - val_accuracy: 0.5085\n",
            "Epoch 785/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9629 - accuracy: 0.6735 - val_loss: 1.4328 - val_accuracy: 0.5090\n",
            "Epoch 786/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9641 - accuracy: 0.6707 - val_loss: 1.5560 - val_accuracy: 0.4900\n",
            "Epoch 787/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9620 - accuracy: 0.6687 - val_loss: 1.5969 - val_accuracy: 0.4630\n",
            "Epoch 788/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9589 - accuracy: 0.6777 - val_loss: 1.8434 - val_accuracy: 0.3885\n",
            "Epoch 789/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9723 - accuracy: 0.6667 - val_loss: 1.5598 - val_accuracy: 0.4735\n",
            "Epoch 790/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9591 - accuracy: 0.6730 - val_loss: 1.5932 - val_accuracy: 0.4700\n",
            "Epoch 791/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9576 - accuracy: 0.6739 - val_loss: 1.6023 - val_accuracy: 0.4620\n",
            "Epoch 792/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9582 - accuracy: 0.6738 - val_loss: 1.6395 - val_accuracy: 0.4450\n",
            "Epoch 793/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9607 - accuracy: 0.6738 - val_loss: 1.5027 - val_accuracy: 0.4985\n",
            "Epoch 794/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9538 - accuracy: 0.6730 - val_loss: 1.5099 - val_accuracy: 0.4910\n",
            "Epoch 795/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9503 - accuracy: 0.6743 - val_loss: 1.6888 - val_accuracy: 0.4385\n",
            "Epoch 796/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9519 - accuracy: 0.6772 - val_loss: 1.4748 - val_accuracy: 0.4965\n",
            "Epoch 797/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9487 - accuracy: 0.6779 - val_loss: 1.7042 - val_accuracy: 0.4445\n",
            "Epoch 798/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9513 - accuracy: 0.6783 - val_loss: 1.4969 - val_accuracy: 0.4840\n",
            "Epoch 799/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.9495 - accuracy: 0.6767 - val_loss: 1.5116 - val_accuracy: 0.4775\n",
            "Epoch 800/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9504 - accuracy: 0.6754 - val_loss: 1.6171 - val_accuracy: 0.4720\n",
            "Epoch 801/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.9478 - accuracy: 0.6783 - val_loss: 1.4279 - val_accuracy: 0.5270\n",
            "Epoch 802/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9457 - accuracy: 0.6809 - val_loss: 1.4879 - val_accuracy: 0.4950\n",
            "Epoch 803/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9429 - accuracy: 0.6811 - val_loss: 1.5878 - val_accuracy: 0.4765\n",
            "Epoch 804/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9456 - accuracy: 0.6789 - val_loss: 1.4115 - val_accuracy: 0.5155\n",
            "Epoch 805/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9444 - accuracy: 0.6794 - val_loss: 1.7177 - val_accuracy: 0.4375\n",
            "Epoch 806/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9520 - accuracy: 0.6757 - val_loss: 1.4666 - val_accuracy: 0.4955\n",
            "Epoch 807/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9421 - accuracy: 0.6826 - val_loss: 1.5937 - val_accuracy: 0.4800\n",
            "Epoch 808/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9473 - accuracy: 0.6778 - val_loss: 1.6628 - val_accuracy: 0.4465\n",
            "Epoch 809/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9436 - accuracy: 0.6800 - val_loss: 1.5873 - val_accuracy: 0.4720\n",
            "Epoch 810/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9417 - accuracy: 0.6778 - val_loss: 1.6963 - val_accuracy: 0.4380\n",
            "Epoch 811/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9407 - accuracy: 0.6803 - val_loss: 1.5894 - val_accuracy: 0.4835\n",
            "Epoch 812/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9390 - accuracy: 0.6795 - val_loss: 1.5113 - val_accuracy: 0.4900\n",
            "Epoch 813/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9350 - accuracy: 0.6842 - val_loss: 1.4136 - val_accuracy: 0.5290\n",
            "Epoch 814/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.9304 - accuracy: 0.6860 - val_loss: 1.5760 - val_accuracy: 0.4695\n",
            "Epoch 815/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9320 - accuracy: 0.6840 - val_loss: 1.4945 - val_accuracy: 0.4855\n",
            "Epoch 816/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9384 - accuracy: 0.6796 - val_loss: 1.5354 - val_accuracy: 0.4810\n",
            "Epoch 817/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9397 - accuracy: 0.6842 - val_loss: 1.4996 - val_accuracy: 0.4945\n",
            "Epoch 818/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9315 - accuracy: 0.6823 - val_loss: 1.7449 - val_accuracy: 0.4235\n",
            "Epoch 819/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9306 - accuracy: 0.6855 - val_loss: 1.4237 - val_accuracy: 0.5095\n",
            "Epoch 820/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9348 - accuracy: 0.6863 - val_loss: 1.4940 - val_accuracy: 0.5030\n",
            "Epoch 821/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9280 - accuracy: 0.6872 - val_loss: 1.5273 - val_accuracy: 0.4995\n",
            "Epoch 822/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9273 - accuracy: 0.6851 - val_loss: 1.5817 - val_accuracy: 0.4840\n",
            "Epoch 823/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9286 - accuracy: 0.6858 - val_loss: 1.9661 - val_accuracy: 0.4310\n",
            "Epoch 824/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.9366 - accuracy: 0.6829 - val_loss: 1.4998 - val_accuracy: 0.4790\n",
            "Epoch 825/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9278 - accuracy: 0.6829 - val_loss: 1.4109 - val_accuracy: 0.5175\n",
            "Epoch 826/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9263 - accuracy: 0.6846 - val_loss: 1.5854 - val_accuracy: 0.4720\n",
            "Epoch 827/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9261 - accuracy: 0.6899 - val_loss: 1.6100 - val_accuracy: 0.4690\n",
            "Epoch 828/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9281 - accuracy: 0.6835 - val_loss: 1.4672 - val_accuracy: 0.5015\n",
            "Epoch 829/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9201 - accuracy: 0.6879 - val_loss: 1.6920 - val_accuracy: 0.4550\n",
            "Epoch 830/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9254 - accuracy: 0.6875 - val_loss: 1.5471 - val_accuracy: 0.4700\n",
            "Epoch 831/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9230 - accuracy: 0.6942 - val_loss: 1.6970 - val_accuracy: 0.4405\n",
            "Epoch 832/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9201 - accuracy: 0.6888 - val_loss: 1.4818 - val_accuracy: 0.4930\n",
            "Epoch 833/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9186 - accuracy: 0.6924 - val_loss: 1.7898 - val_accuracy: 0.4515\n",
            "Epoch 834/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9207 - accuracy: 0.6896 - val_loss: 1.4809 - val_accuracy: 0.4980\n",
            "Epoch 835/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9127 - accuracy: 0.6896 - val_loss: 1.5409 - val_accuracy: 0.4830\n",
            "Epoch 836/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9109 - accuracy: 0.6906 - val_loss: 1.4704 - val_accuracy: 0.5005\n",
            "Epoch 837/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9142 - accuracy: 0.6913 - val_loss: 1.5433 - val_accuracy: 0.4815\n",
            "Epoch 838/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9139 - accuracy: 0.6906 - val_loss: 1.6414 - val_accuracy: 0.4655\n",
            "Epoch 839/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.9139 - accuracy: 0.6904 - val_loss: 1.4923 - val_accuracy: 0.4895\n",
            "Epoch 840/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9071 - accuracy: 0.6975 - val_loss: 1.5043 - val_accuracy: 0.4990\n",
            "Epoch 841/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9074 - accuracy: 0.6932 - val_loss: 1.5772 - val_accuracy: 0.4760\n",
            "Epoch 842/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9064 - accuracy: 0.6933 - val_loss: 1.5619 - val_accuracy: 0.4810\n",
            "Epoch 843/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9123 - accuracy: 0.6905 - val_loss: 1.4395 - val_accuracy: 0.5120\n",
            "Epoch 844/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9000 - accuracy: 0.6945 - val_loss: 1.6586 - val_accuracy: 0.4460\n",
            "Epoch 845/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9067 - accuracy: 0.6920 - val_loss: 1.4587 - val_accuracy: 0.5050\n",
            "Epoch 846/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9003 - accuracy: 0.6971 - val_loss: 1.4733 - val_accuracy: 0.4885\n",
            "Epoch 847/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9022 - accuracy: 0.6942 - val_loss: 1.5884 - val_accuracy: 0.4890\n",
            "Epoch 848/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9017 - accuracy: 0.6934 - val_loss: 1.5009 - val_accuracy: 0.4915\n",
            "Epoch 849/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9087 - accuracy: 0.6930 - val_loss: 1.4733 - val_accuracy: 0.5080\n",
            "Epoch 850/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9010 - accuracy: 0.6953 - val_loss: 1.4838 - val_accuracy: 0.4890\n",
            "Epoch 851/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9006 - accuracy: 0.6953 - val_loss: 1.7590 - val_accuracy: 0.4520\n",
            "Epoch 852/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9017 - accuracy: 0.6983 - val_loss: 1.5531 - val_accuracy: 0.4880\n",
            "Epoch 853/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.9009 - accuracy: 0.6975 - val_loss: 1.4771 - val_accuracy: 0.5045\n",
            "Epoch 854/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8965 - accuracy: 0.6964 - val_loss: 1.6935 - val_accuracy: 0.4495\n",
            "Epoch 855/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8961 - accuracy: 0.6984 - val_loss: 1.4973 - val_accuracy: 0.5040\n",
            "Epoch 856/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8955 - accuracy: 0.6965 - val_loss: 1.6828 - val_accuracy: 0.4495\n",
            "Epoch 857/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8908 - accuracy: 0.6998 - val_loss: 1.5092 - val_accuracy: 0.4870\n",
            "Epoch 858/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8912 - accuracy: 0.6976 - val_loss: 1.4147 - val_accuracy: 0.5185\n",
            "Epoch 859/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8881 - accuracy: 0.7028 - val_loss: 1.5014 - val_accuracy: 0.4945\n",
            "Epoch 860/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8933 - accuracy: 0.6990 - val_loss: 1.5974 - val_accuracy: 0.4745\n",
            "Epoch 861/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8913 - accuracy: 0.7010 - val_loss: 1.5386 - val_accuracy: 0.4845\n",
            "Epoch 862/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8894 - accuracy: 0.6992 - val_loss: 1.6856 - val_accuracy: 0.4475\n",
            "Epoch 863/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8928 - accuracy: 0.7002 - val_loss: 1.6380 - val_accuracy: 0.4645\n",
            "Epoch 864/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8908 - accuracy: 0.7005 - val_loss: 1.6553 - val_accuracy: 0.4805\n",
            "Epoch 865/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8889 - accuracy: 0.7009 - val_loss: 1.5209 - val_accuracy: 0.5010\n",
            "Epoch 866/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8900 - accuracy: 0.7024 - val_loss: 1.4691 - val_accuracy: 0.5080\n",
            "Epoch 867/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8822 - accuracy: 0.7034 - val_loss: 1.6928 - val_accuracy: 0.4330\n",
            "Epoch 868/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8837 - accuracy: 0.7038 - val_loss: 1.4802 - val_accuracy: 0.5025\n",
            "Epoch 869/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8859 - accuracy: 0.7023 - val_loss: 1.5426 - val_accuracy: 0.4825\n",
            "Epoch 870/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8845 - accuracy: 0.7033 - val_loss: 1.4756 - val_accuracy: 0.5010\n",
            "Epoch 871/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8796 - accuracy: 0.7055 - val_loss: 1.4937 - val_accuracy: 0.4950\n",
            "Epoch 872/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8835 - accuracy: 0.7056 - val_loss: 1.6675 - val_accuracy: 0.4610\n",
            "Epoch 873/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8776 - accuracy: 0.7052 - val_loss: 1.6321 - val_accuracy: 0.4840\n",
            "Epoch 874/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8828 - accuracy: 0.7032 - val_loss: 1.7214 - val_accuracy: 0.4555\n",
            "Epoch 875/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8803 - accuracy: 0.7038 - val_loss: 1.5915 - val_accuracy: 0.4835\n",
            "Epoch 876/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8745 - accuracy: 0.7081 - val_loss: 1.5683 - val_accuracy: 0.4940\n",
            "Epoch 877/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8701 - accuracy: 0.7072 - val_loss: 1.4801 - val_accuracy: 0.5025\n",
            "Epoch 878/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8757 - accuracy: 0.7069 - val_loss: 1.4578 - val_accuracy: 0.5180\n",
            "Epoch 879/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8679 - accuracy: 0.7064 - val_loss: 1.6011 - val_accuracy: 0.4635\n",
            "Epoch 880/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8782 - accuracy: 0.7071 - val_loss: 1.5067 - val_accuracy: 0.4970\n",
            "Epoch 881/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8707 - accuracy: 0.7067 - val_loss: 1.4217 - val_accuracy: 0.5175\n",
            "Epoch 882/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8644 - accuracy: 0.7081 - val_loss: 1.5425 - val_accuracy: 0.4900\n",
            "Epoch 883/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8727 - accuracy: 0.7092 - val_loss: 1.6708 - val_accuracy: 0.4840\n",
            "Epoch 884/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8696 - accuracy: 0.7078 - val_loss: 1.5139 - val_accuracy: 0.4985\n",
            "Epoch 885/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8648 - accuracy: 0.7109 - val_loss: 1.6845 - val_accuracy: 0.4485\n",
            "Epoch 886/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8710 - accuracy: 0.7092 - val_loss: 1.4875 - val_accuracy: 0.5045\n",
            "Epoch 887/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8673 - accuracy: 0.7080 - val_loss: 1.5849 - val_accuracy: 0.4820\n",
            "Epoch 888/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8613 - accuracy: 0.7104 - val_loss: 1.4724 - val_accuracy: 0.5210\n",
            "Epoch 889/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8590 - accuracy: 0.7132 - val_loss: 1.5139 - val_accuracy: 0.4860\n",
            "Epoch 890/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8649 - accuracy: 0.7065 - val_loss: 1.5512 - val_accuracy: 0.4970\n",
            "Epoch 891/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8576 - accuracy: 0.7135 - val_loss: 2.0067 - val_accuracy: 0.4030\n",
            "Epoch 892/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8656 - accuracy: 0.7116 - val_loss: 1.8520 - val_accuracy: 0.4410\n",
            "Epoch 893/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8659 - accuracy: 0.7082 - val_loss: 1.4223 - val_accuracy: 0.5255\n",
            "Epoch 894/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8577 - accuracy: 0.7160 - val_loss: 1.4875 - val_accuracy: 0.4985\n",
            "Epoch 895/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8560 - accuracy: 0.7147 - val_loss: 1.6375 - val_accuracy: 0.4660\n",
            "Epoch 896/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8598 - accuracy: 0.7089 - val_loss: 1.9047 - val_accuracy: 0.4070\n",
            "Epoch 897/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8538 - accuracy: 0.7146 - val_loss: 1.4357 - val_accuracy: 0.5125\n",
            "Epoch 898/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8489 - accuracy: 0.7156 - val_loss: 1.4876 - val_accuracy: 0.5135\n",
            "Epoch 899/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8544 - accuracy: 0.7117 - val_loss: 1.4959 - val_accuracy: 0.4950\n",
            "Epoch 900/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8520 - accuracy: 0.7142 - val_loss: 1.5021 - val_accuracy: 0.4935\n",
            "Epoch 901/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8576 - accuracy: 0.7131 - val_loss: 1.6941 - val_accuracy: 0.4615\n",
            "Epoch 902/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8599 - accuracy: 0.7089 - val_loss: 1.9087 - val_accuracy: 0.4380\n",
            "Epoch 903/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8581 - accuracy: 0.7125 - val_loss: 1.4880 - val_accuracy: 0.5005\n",
            "Epoch 904/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8450 - accuracy: 0.7153 - val_loss: 1.5358 - val_accuracy: 0.4980\n",
            "Epoch 905/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8436 - accuracy: 0.7207 - val_loss: 1.5350 - val_accuracy: 0.4960\n",
            "Epoch 906/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8478 - accuracy: 0.7180 - val_loss: 1.5045 - val_accuracy: 0.5065\n",
            "Epoch 907/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8516 - accuracy: 0.7137 - val_loss: 1.4566 - val_accuracy: 0.5060\n",
            "Epoch 908/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8417 - accuracy: 0.7227 - val_loss: 2.1498 - val_accuracy: 0.4125\n",
            "Epoch 909/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8443 - accuracy: 0.7196 - val_loss: 1.5788 - val_accuracy: 0.4815\n",
            "Epoch 910/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8447 - accuracy: 0.7171 - val_loss: 1.5265 - val_accuracy: 0.4895\n",
            "Epoch 911/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8435 - accuracy: 0.7192 - val_loss: 1.4782 - val_accuracy: 0.5055\n",
            "Epoch 912/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8389 - accuracy: 0.7179 - val_loss: 1.4699 - val_accuracy: 0.5090\n",
            "Epoch 913/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8397 - accuracy: 0.7219 - val_loss: 1.5888 - val_accuracy: 0.4730\n",
            "Epoch 914/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8425 - accuracy: 0.7181 - val_loss: 1.6346 - val_accuracy: 0.4700\n",
            "Epoch 915/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8390 - accuracy: 0.7214 - val_loss: 1.6859 - val_accuracy: 0.4765\n",
            "Epoch 916/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8434 - accuracy: 0.7194 - val_loss: 1.6436 - val_accuracy: 0.4680\n",
            "Epoch 917/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8372 - accuracy: 0.7234 - val_loss: 1.5327 - val_accuracy: 0.4975\n",
            "Epoch 918/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8343 - accuracy: 0.7222 - val_loss: 1.5561 - val_accuracy: 0.4865\n",
            "Epoch 919/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8392 - accuracy: 0.7185 - val_loss: 1.5075 - val_accuracy: 0.4885\n",
            "Epoch 920/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8345 - accuracy: 0.7202 - val_loss: 1.5306 - val_accuracy: 0.5015\n",
            "Epoch 921/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8351 - accuracy: 0.7249 - val_loss: 1.5731 - val_accuracy: 0.4645\n",
            "Epoch 922/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8323 - accuracy: 0.7224 - val_loss: 1.5342 - val_accuracy: 0.4895\n",
            "Epoch 923/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8311 - accuracy: 0.7248 - val_loss: 1.5208 - val_accuracy: 0.4945\n",
            "Epoch 924/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8259 - accuracy: 0.7272 - val_loss: 1.4585 - val_accuracy: 0.5105\n",
            "Epoch 925/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8234 - accuracy: 0.7279 - val_loss: 1.4257 - val_accuracy: 0.5270\n",
            "Epoch 926/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8304 - accuracy: 0.7253 - val_loss: 1.4986 - val_accuracy: 0.4990\n",
            "Epoch 927/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8253 - accuracy: 0.7266 - val_loss: 1.5196 - val_accuracy: 0.4895\n",
            "Epoch 928/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8242 - accuracy: 0.7248 - val_loss: 1.6747 - val_accuracy: 0.4640\n",
            "Epoch 929/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8254 - accuracy: 0.7257 - val_loss: 1.5192 - val_accuracy: 0.4805\n",
            "Epoch 930/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8232 - accuracy: 0.7298 - val_loss: 1.5796 - val_accuracy: 0.4625\n",
            "Epoch 931/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8255 - accuracy: 0.7262 - val_loss: 1.5107 - val_accuracy: 0.4975\n",
            "Epoch 932/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8181 - accuracy: 0.7269 - val_loss: 1.5603 - val_accuracy: 0.4835\n",
            "Epoch 933/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8156 - accuracy: 0.7298 - val_loss: 1.4943 - val_accuracy: 0.4985\n",
            "Epoch 934/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8153 - accuracy: 0.7280 - val_loss: 1.8990 - val_accuracy: 0.4390\n",
            "Epoch 935/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8244 - accuracy: 0.7273 - val_loss: 1.6341 - val_accuracy: 0.4675\n",
            "Epoch 936/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8181 - accuracy: 0.7286 - val_loss: 1.6034 - val_accuracy: 0.4905\n",
            "Epoch 937/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8102 - accuracy: 0.7320 - val_loss: 1.4970 - val_accuracy: 0.5125\n",
            "Epoch 938/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8078 - accuracy: 0.7356 - val_loss: 1.5738 - val_accuracy: 0.4940\n",
            "Epoch 939/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8199 - accuracy: 0.7260 - val_loss: 1.4649 - val_accuracy: 0.5205\n",
            "Epoch 940/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8109 - accuracy: 0.7358 - val_loss: 1.5842 - val_accuracy: 0.4810\n",
            "Epoch 941/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8049 - accuracy: 0.7334 - val_loss: 1.5571 - val_accuracy: 0.4870\n",
            "Epoch 942/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8066 - accuracy: 0.7333 - val_loss: 1.5293 - val_accuracy: 0.4885\n",
            "Epoch 943/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8153 - accuracy: 0.7262 - val_loss: 1.5546 - val_accuracy: 0.4920\n",
            "Epoch 944/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8115 - accuracy: 0.7319 - val_loss: 1.5941 - val_accuracy: 0.4790\n",
            "Epoch 945/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8098 - accuracy: 0.7339 - val_loss: 1.5201 - val_accuracy: 0.4940\n",
            "Epoch 946/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8021 - accuracy: 0.7359 - val_loss: 1.6700 - val_accuracy: 0.4595\n",
            "Epoch 947/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8064 - accuracy: 0.7361 - val_loss: 1.5777 - val_accuracy: 0.4835\n",
            "Epoch 948/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.8044 - accuracy: 0.7342 - val_loss: 1.6419 - val_accuracy: 0.4835\n",
            "Epoch 949/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8038 - accuracy: 0.7345 - val_loss: 1.5426 - val_accuracy: 0.4865\n",
            "Epoch 950/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8012 - accuracy: 0.7327 - val_loss: 1.5798 - val_accuracy: 0.5030\n",
            "Epoch 951/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8048 - accuracy: 0.7303 - val_loss: 1.5711 - val_accuracy: 0.4995\n",
            "Epoch 952/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8071 - accuracy: 0.7301 - val_loss: 2.0380 - val_accuracy: 0.4000\n",
            "Epoch 953/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8137 - accuracy: 0.7271 - val_loss: 1.5311 - val_accuracy: 0.4940\n",
            "Epoch 954/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.8010 - accuracy: 0.7338 - val_loss: 1.5812 - val_accuracy: 0.4890\n",
            "Epoch 955/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7991 - accuracy: 0.7341 - val_loss: 1.7787 - val_accuracy: 0.4605\n",
            "Epoch 956/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7968 - accuracy: 0.7371 - val_loss: 1.5525 - val_accuracy: 0.4845\n",
            "Epoch 957/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7946 - accuracy: 0.7375 - val_loss: 1.4621 - val_accuracy: 0.5140\n",
            "Epoch 958/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7888 - accuracy: 0.7431 - val_loss: 1.5661 - val_accuracy: 0.4885\n",
            "Epoch 959/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7935 - accuracy: 0.7347 - val_loss: 1.9800 - val_accuracy: 0.4240\n",
            "Epoch 960/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7986 - accuracy: 0.7348 - val_loss: 1.5673 - val_accuracy: 0.4940\n",
            "Epoch 961/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7919 - accuracy: 0.7401 - val_loss: 1.5261 - val_accuracy: 0.4930\n",
            "Epoch 962/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7880 - accuracy: 0.7422 - val_loss: 1.6082 - val_accuracy: 0.4760\n",
            "Epoch 963/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7913 - accuracy: 0.7386 - val_loss: 1.4712 - val_accuracy: 0.5085\n",
            "Epoch 964/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7839 - accuracy: 0.7423 - val_loss: 1.6566 - val_accuracy: 0.4490\n",
            "Epoch 965/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7915 - accuracy: 0.7379 - val_loss: 1.4758 - val_accuracy: 0.5130\n",
            "Epoch 966/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7824 - accuracy: 0.7415 - val_loss: 1.9469 - val_accuracy: 0.4195\n",
            "Epoch 967/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7911 - accuracy: 0.7367 - val_loss: 1.6380 - val_accuracy: 0.4670\n",
            "Epoch 968/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7831 - accuracy: 0.7402 - val_loss: 1.6830 - val_accuracy: 0.4640\n",
            "Epoch 969/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7827 - accuracy: 0.7411 - val_loss: 1.7897 - val_accuracy: 0.4370\n",
            "Epoch 970/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7850 - accuracy: 0.7412 - val_loss: 1.5350 - val_accuracy: 0.5030\n",
            "Epoch 971/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7779 - accuracy: 0.7440 - val_loss: 1.5520 - val_accuracy: 0.5020\n",
            "Epoch 972/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7762 - accuracy: 0.7431 - val_loss: 1.6119 - val_accuracy: 0.4830\n",
            "Epoch 973/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7810 - accuracy: 0.7400 - val_loss: 1.5597 - val_accuracy: 0.4930\n",
            "Epoch 974/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7793 - accuracy: 0.7434 - val_loss: 1.6518 - val_accuracy: 0.4660\n",
            "Epoch 975/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7815 - accuracy: 0.7415 - val_loss: 1.7894 - val_accuracy: 0.4495\n",
            "Epoch 976/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7767 - accuracy: 0.7427 - val_loss: 1.6070 - val_accuracy: 0.4780\n",
            "Epoch 977/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7800 - accuracy: 0.7422 - val_loss: 1.4742 - val_accuracy: 0.5145\n",
            "Epoch 978/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7712 - accuracy: 0.7502 - val_loss: 1.8098 - val_accuracy: 0.4590\n",
            "Epoch 979/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7802 - accuracy: 0.7421 - val_loss: 1.8020 - val_accuracy: 0.4640\n",
            "Epoch 980/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7772 - accuracy: 0.7444 - val_loss: 1.5339 - val_accuracy: 0.5060\n",
            "Epoch 981/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7758 - accuracy: 0.7455 - val_loss: 1.5144 - val_accuracy: 0.5110\n",
            "Epoch 982/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7746 - accuracy: 0.7450 - val_loss: 1.7509 - val_accuracy: 0.4480\n",
            "Epoch 983/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7709 - accuracy: 0.7476 - val_loss: 1.7503 - val_accuracy: 0.4515\n",
            "Epoch 984/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7726 - accuracy: 0.7457 - val_loss: 1.7639 - val_accuracy: 0.4855\n",
            "Epoch 985/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7710 - accuracy: 0.7431 - val_loss: 1.6765 - val_accuracy: 0.4485\n",
            "Epoch 986/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7687 - accuracy: 0.7480 - val_loss: 1.6823 - val_accuracy: 0.4735\n",
            "Epoch 987/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7707 - accuracy: 0.7457 - val_loss: 1.5024 - val_accuracy: 0.4980\n",
            "Epoch 988/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7697 - accuracy: 0.7491 - val_loss: 1.8078 - val_accuracy: 0.4360\n",
            "Epoch 989/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7672 - accuracy: 0.7452 - val_loss: 1.4977 - val_accuracy: 0.5090\n",
            "Epoch 990/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7626 - accuracy: 0.7486 - val_loss: 1.6024 - val_accuracy: 0.4850\n",
            "Epoch 991/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7571 - accuracy: 0.7529 - val_loss: 1.5295 - val_accuracy: 0.4905\n",
            "Epoch 992/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7634 - accuracy: 0.7491 - val_loss: 1.5375 - val_accuracy: 0.4940\n",
            "Epoch 993/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7579 - accuracy: 0.7540 - val_loss: 2.1276 - val_accuracy: 0.3975\n",
            "Epoch 994/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7693 - accuracy: 0.7453 - val_loss: 1.5075 - val_accuracy: 0.5000\n",
            "Epoch 995/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7577 - accuracy: 0.7519 - val_loss: 1.4773 - val_accuracy: 0.5165\n",
            "Epoch 996/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7596 - accuracy: 0.7476 - val_loss: 1.5927 - val_accuracy: 0.5025\n",
            "Epoch 997/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7515 - accuracy: 0.7568 - val_loss: 1.4795 - val_accuracy: 0.5090\n",
            "Epoch 998/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7520 - accuracy: 0.7534 - val_loss: 2.1097 - val_accuracy: 0.4065\n",
            "Epoch 999/1000\n",
            "79/79 [==============================] - 0s 5ms/step - loss: 0.7605 - accuracy: 0.7518 - val_loss: 1.7015 - val_accuracy: 0.4635\n",
            "Epoch 1000/1000\n",
            "79/79 [==============================] - 0s 6ms/step - loss: 0.7551 - accuracy: 0.7480 - val_loss: 1.5972 - val_accuracy: 0.4905\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m45dUurYQyPs",
        "outputId": "ebd5e177-aa8e-47e1-a739-4d93b56ef79e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Save model\n",
        "if use_dropout:\n",
        "    model.save(f'/content/gdrive/My Drive/Colab Output/models/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout')\n",
        "else:\n",
        "    model.save(f'/content/gdrive/My Drive/Colab Output/models/{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/My Drive/Colab Output/models/50_60_SGD_no_dropout/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDBkEeOwXcFA"
      },
      "source": [
        "# Extract Loss Values\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Extract Accuracy Values\n",
        "train_acc = history.history['accuracy']\n",
        "test_acc = history.history['val_accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EeJSJWRZi6e"
      },
      "source": [
        "# Save instanced variables w/ pickle rick\n",
        "instanced_variables = [train_loss, val_loss, train_acc, test_acc]\n",
        "\n",
        "filename = '/content/gdrive/My Drive/Colab Output/part_a_q1_variables'\n",
        "outfile = open(filename,'wb')\n",
        "\n",
        "pickle.dump(instanced_variables, outfile)\n",
        "outfile.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN_bQ_d6aXEy"
      },
      "source": [
        "# Retrieve previously saved instanced variables w/ pickle rick\n",
        "infile = open('/content/gdrive/My Drive/Colab Output/part_a_q1_variables', 'rb')\n",
        "retrieved_variables = pickle.load(infile)\n",
        "infile.close()\n",
        "\n",
        "# Load retrieved variables into instance variables for plotting\n",
        "train_loss, val_loss, train_acc, test_acc = retrieved_variables"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjNn4jxNqURE",
        "outputId": "66b25c8b-7800-4372-e4dc-ce6e58537ab9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# get highest accuracy values\n",
        "highest_acc = max(test_acc)\n",
        "\n",
        "# get average accuracy\n",
        "average_acc = sum(test_acc)/len(test_acc)\n",
        "\n",
        "print('Highest Acc')\n",
        "print(highest_acc)\n",
        "\n",
        "print('')\n",
        "\n",
        "print('Avg Acc')\n",
        "print(average_acc)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Highest Acc\n",
            "0.5289999842643738\n",
            "\n",
            "Avg Acc\n",
            "0.4440570002943277\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNg1SvzMQznQ",
        "outputId": "95164467-dbac-4a09-bdeb-523de84787dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Save the plot for loss\n",
        "plt.plot(range(1, len(train_loss) + 1), train_loss, label='Train')\n",
        "plt.plot(range(1, len(val_loss) + 1), val_loss, label='Test')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "if use_dropout:\n",
        "    plt.savefig(f'/content/gdrive/My Drive/Colab Output/results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout_loss.pdf')\n",
        "    plt.savefig(f'/content/gdrive/My Drive/Colab Output/results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout_loss.png')\n",
        "else:\n",
        "    plt.savefig(f'/content/gdrive/My Drive/Colab Output/results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout_loss.pdf')\n",
        "    plt.savefig(f'/content/gdrive/My Drive/Colab Output/results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout_loss.png')\n",
        "#plt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP3WFqMIQ0WJ",
        "outputId": "29fdfaf8-3e62-4c11-cda0-8d3f5e65e847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Save the plot for accuracies\n",
        "plt.plot(range(1, len(train_acc) + 1), train_acc, label='Train')\n",
        "plt.plot(range(1, len(test_acc) + 1), test_acc, label='Test')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend()\n",
        "if use_dropout:\n",
        "    plt.savefig(f'/content/gdrive/My Drive/Colab Output/results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout_accuracy.pdf')\n",
        "    plt.savefig(f'/content/gdrive/My Drive/Colab Output/results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_dropout_accuracy.png')\n",
        "else:\n",
        "    plt.savefig(f'/content/gdrive/My Drive/Colab Output/results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout_accuracy.pdf')\n",
        "    plt.savefig(f'/content/gdrive/My Drive/Colab Output/results/{num_ch_c1}_{num_ch_c2}_{optimizer_}_no_dropout_accuracy.png')\n",
        "#plt.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfeaPzMaPJg6"
      },
      "source": [
        "# load data from file\n",
        "def load_data(file):\n",
        "    with open(file, 'rb') as fo:\n",
        "        try:\n",
        "            samples = pickle.load(fo)\n",
        "        except UnicodeDecodeError:  # python 3.x\n",
        "            fo.seek(0)\n",
        "            samples = pickle.load(fo, encoding='latin1')\n",
        "\n",
        "    data, labels = samples['data'], samples['labels']\n",
        "    \n",
        "    # normalization\n",
        "    data = np.array(data, dtype=np.float32) / 255\n",
        "    \n",
        "    # reshape x_train and x_test into (32,32,3) before using as input for model\n",
        "    R = data[:,0:1024].reshape(-1,32,32) \n",
        "    G = data[:,1024:2048].reshape(-1,32,32) \n",
        "    B = data[:,2048:].reshape(-1,32,32)\n",
        "    data = np.stack((R,G,B),axis=3) \n",
        "    \n",
        "    labels = np.array(labels, dtype=np.int32)\n",
        "    \n",
        "    return data, labels"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}